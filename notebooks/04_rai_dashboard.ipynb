{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASHBOARD DE INTELIGENCIA ARTIFICIAL RESPONSABLE (RAI)\n",
    "# ================================================================\n",
    "\n",
    "# 1. CONFIGURACI√ìN Y IMPORTS PARA RAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import shap\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Azure ML imports\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run, Model\n",
    "from azureml.core.model import Model as AMLModel\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# RAI y an√°lisis de equidad\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# An√°lisis estad√≠stico\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ks_2samp\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üõ°Ô∏è  DASHBOARD DE INTELIGENCIA ARTIFICIAL RESPONSABLE\")\n",
    "print(\"=\"*70)\n",
    "print(\"üìã An√°lisis de: Equidad, Explicabilidad, Robustez y Transparencia\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Conectar al workspace\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(f\"‚úÖ Conectado al workspace: {ws.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error conectando al workspace: {e}\")\n",
    "    raise\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "print(f\"üîÑ Cargando modelo y datos para an√°lisis RAI...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CARGA DE MODELO Y DATOS PARA AN√ÅLISIS RAI\n",
    "print(\"\\nüì• CARGA DE MODELO Y DATOS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Cargar el modelo registrado m√°s reciente\n",
    "MODEL_NAME = \"candidate-selection-model\"\n",
    "\n",
    "try:\n",
    "    # Obtener la versi√≥n m√°s reciente del modelo\n",
    "    registered_model = AMLModel(ws, name=MODEL_NAME)\n",
    "    print(f\"‚úÖ Modelo encontrado: {MODEL_NAME}\")\n",
    "    print(f\"üìã Versi√≥n: {registered_model.version}\")\n",
    "    \n",
    "    # Descargar artefactos del modelo\n",
    "    model_path = registered_model.download(target_dir=\"./model_artifacts\")\n",
    "    print(f\"üìÅ Artefactos descargados en: {model_path}\")\n",
    "    \n",
    "    # Cargar modelo y scaler\n",
    "    model = joblib.load(f\"{model_path}/model.pkl\")\n",
    "    scaler = joblib.load(f\"{model_path}/scaler.pkl\")\n",
    "    \n",
    "    # Cargar metadatos\n",
    "    with open(f\"{model_path}/feature_names.json\", 'r') as f:\n",
    "        feature_metadata = json.load(f)\n",
    "    \n",
    "    with open(f\"{model_path}/notebook_info.json\", 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Modelo cargado: {type(model).__name__}\")\n",
    "    print(f\"üìä Features: {feature_metadata['feature_count']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando modelo registrado: {e}\")\n",
    "    print(\"üí° Aseg√∫rate de haber ejecutado el notebook de entrenamiento primero\")\n",
    "    raise\n",
    "\n",
    "# Cargar datasets\n",
    "try:\n",
    "    # Cargar datos de test y validaci√≥n\n",
    "    test_data = pd.read_parquet(f\"{model_path}/test_data.parquet\")\n",
    "    val_data = pd.read_parquet(f\"{model_path}/val_data.parquet\")\n",
    "    \n",
    "    print(f\"\\nüìä Datos cargados:\")\n",
    "    print(f\"  Test: {test_data.shape}\")\n",
    "    print(f\"  Validaci√≥n: {val_data.shape}\")\n",
    "    \n",
    "    # Separar features y targets\n",
    "    feature_names = feature_metadata['feature_names']\n",
    "    \n",
    "    X_test = test_data[feature_names]\n",
    "    y_test_true = test_data['y_true']\n",
    "    y_test_pred = test_data['y_pred']\n",
    "    y_test_proba = test_data['y_proba']\n",
    "    \n",
    "    # Combinar datos para an√°lisis m√°s completo\n",
    "    X_combined = pd.concat([X_test, val_data[feature_names]], ignore_index=True)\n",
    "    y_combined_true = pd.concat([y_test_true, val_data['y_true']], ignore_index=True)\n",
    "    y_combined_pred = pd.concat([y_test_pred, val_data['y_pred']], ignore_index=True)\n",
    "    y_combined_proba = pd.concat([y_test_proba, val_data['y_proba']], ignore_index=True)\n",
    "    \n",
    "    print(f\"  Datos combinados: {X_combined.shape}\")\n",
    "    print(f\"‚úÖ Datos organizados para an√°lisis RAI\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando datos: {e}\")\n",
    "    raise\n",
    "\n",
    "# Cargar datos originales procesados para an√°lisis de equidad\n",
    "try:\n",
    "    # Intentar cargar datos procesados con informaci√≥n demogr√°fica\n",
    "    processed_data_path = \"data/processed/processed_candidates.parquet\"\n",
    "    if Path(processed_data_path).exists():\n",
    "        full_processed_data = pd.read_parquet(processed_data_path)\n",
    "        print(f\"üìä Datos originales cargados: {full_processed_data.shape}\")\n",
    "        \n",
    "        # Verificar columnas disponibles para an√°lisis de equidad\n",
    "        demographic_cols = []\n",
    "        if 'gender' in full_processed_data.columns:\n",
    "            demographic_cols.append('gender')\n",
    "        if 'age_range' in full_processed_data.columns:\n",
    "            demographic_cols.append('age_range')\n",
    "        if 'location' in full_processed_data.columns:\n",
    "            demographic_cols.append('location')\n",
    "        if 'education_level' in full_processed_data.columns:\n",
    "            demographic_cols.append('education_level')\n",
    "            \n",
    "        print(f\"üìã Columnas demogr√°ficas disponibles: {demographic_cols}\")\n",
    "        demographic_data_available = len(demographic_cols) > 0\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Datos originales no encontrados - an√°lisis de equidad limitado\")\n",
    "        demographic_data_available = False\n",
    "        full_processed_data = None\n",
    "        demographic_cols = []\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error cargando datos demogr√°ficos: {e}\")\n",
    "    demographic_data_available = False\n",
    "    full_processed_data = None\n",
    "    demographic_cols = []\n",
    "\n",
    "print(f\"\\nüìã CONFIGURACI√ìN PARA AN√ÅLISIS RAI:\")\n",
    "print(f\"  Modelo: {training_info['best_model_name']}\")\n",
    "print(f\"  Muestras para an√°lisis: {len(X_combined):,}\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"  An√°lisis demogr√°fico: {'‚úÖ Disponible' if demographic_data_available else '‚ùå No disponible'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AN√ÅLISIS DE EXPLICABILIDAD CON SHAP\n",
    "print(\"\\nüîç AN√ÅLISIS DE EXPLICABILIDAD DEL MODELO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def analyze_model_explainability(model, X_sample, feature_names, max_samples=500):\n",
    "    \"\"\"Realiza an√°lisis completo de explicabilidad usando SHAP\"\"\"\n",
    "    \n",
    "    explainability_results = {}\n",
    "    \n",
    "    # Tomar muestra para SHAP (computacionalmente costoso)\n",
    "    if len(X_sample) > max_samples:\n",
    "        sample_idx = np.random.choice(len(X_sample), max_samples, replace=False)\n",
    "        X_shap = X_sample.iloc[sample_idx]\n",
    "        print(f\"üìä Usando muestra de {max_samples} observaciones para SHAP\")\n",
    "    else:\n",
    "        X_shap = X_sample\n",
    "        print(f\"üìä Usando todas las {len(X_sample)} observaciones para SHAP\")\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Calculando valores SHAP...\")\n",
    "        \n",
    "        # Crear explainer seg√∫n tipo de modelo\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            # Para modelos probabil√≠sticos\n",
    "            if hasattr(model, 'tree_'):\n",
    "                # Modelos basados en √°rboles\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "            else:\n",
    "                # Otros modelos - usar KernelExplainer\n",
    "                explainer = shap.KernelExplainer(\n",
    "                    model.predict_proba, \n",
    "                    X_shap.sample(min(100, len(X_shap)))\n",
    "                )\n",
    "        else:\n",
    "            # Modelos de regresi√≥n\n",
    "            explainer = shap.KernelExplainer(\n",
    "                model.predict, \n",
    "                X_shap.sample(min(100, len(X_shap)))\n",
    "            )\n",
    "        \n",
    "        # Calcular valores SHAP\n",
    "        shap_values = explainer.shap_values(X_shap)\n",
    "        \n",
    "        # Para modelos de clasificaci√≥n binaria, tomar valores para clase positiva\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values_positive = shap_values[1]\n",
    "        else:\n",
    "            shap_values_positive = shap_values\n",
    "        \n",
    "        explainability_results['shap_values'] = shap_values_positive\n",
    "        explainability_results['shap_data'] = X_shap\n",
    "        explainability_results['explainer'] = explainer\n",
    "        \n",
    "        # Calcular importancia global\n",
    "        feature_importance_shap = np.abs(shap_values_positive).mean(axis=0)\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance_shap\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        explainability_results['global_importance'] = importance_df\n",
    "        \n",
    "        print(\"‚úÖ An√°lisis SHAP completado\")\n",
    "        \n",
    "        return explainability_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en an√°lisis SHAP: {e}\")\n",
    "        print(\"üìù Realizando an√°lisis de explicabilidad alternativo...\")\n",
    "        \n",
    "        # An√°lisis alternativo usando permutation importance\n",
    "        try:\n",
    "            perm_importance = permutation_importance(\n",
    "                model, X_shap, \n",
    "                model.predict(X_shap) if not hasattr(model, 'predict_proba') else np.argmax(model.predict_proba(X_shap), axis=1),\n",
    "                n_repeats=5, random_state=42\n",
    "            )\n",
    "            \n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': perm_importance.importances_mean\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            explainability_results['global_importance'] = importance_df\n",
    "            explainability_results['shap_available'] = False\n",
    "            \n",
    "            print(\"‚úÖ An√°lisis de explicabilidad alternativo completado\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Error en an√°lisis alternativo: {e2}\")\n",
    "            explainability_results['error'] = str(e2)\n",
    "        \n",
    "        return explainability_results\n",
    "\n",
    "# Realizar an√°lisis de explicabilidad\n",
    "explainability_analysis = analyze_model_explainability(\n",
    "    model, X_combined, feature_names, max_samples=300\n",
    ")\n",
    "\n",
    "# Visualizar resultados de explicabilidad\n",
    "if 'global_importance' in explainability_analysis:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Importancia global de caracter√≠sticas\n",
    "    top_features = explainability_analysis['global_importance'].head(15)\n",
    "    \n",
    "    axes[0,0].barh(range(len(top_features)), top_features['importance'])\n",
    "    axes[0,0].set_yticks(range(len(top_features)))\n",
    "    axes[0,0].set_yticklabels(top_features['feature'])\n",
    "    axes[0,0].set_xlabel('Importancia Global')\n",
    "    axes[0,0].set_title('Top 15 Caracter√≠sticas m√°s Importantes\\n(An√°lisis de Explicabilidad)')\n",
    "    axes[0,0].invert_yaxis()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Distribuci√≥n de importancias\n",
    "    axes[0,1].hist(explainability_analysis['global_importance']['importance'], \n",
    "                   bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].set_xlabel('Importancia')\n",
    "    axes[0,1].set_ylabel('Frecuencia')\n",
    "    axes[0,1].set_title('Distribuci√≥n de Importancias')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Importancia acumulada\n",
    "    sorted_importance = explainability_analysis['global_importance'].sort_values('importance', ascending=False)\n",
    "    cumulative_importance = np.cumsum(sorted_importance['importance']) / sorted_importance['importance'].sum()\n",
    "    \n",
    "    axes[1,0].plot(range(1, len(cumulative_importance) + 1), cumulative_importance, 'b-', linewidth=2)\n",
    "    axes[1,0].axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80% importancia')\n",
    "    axes[1,0].axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='90% importancia')\n",
    "    axes[1,0].set_xlabel('N√∫mero de Caracter√≠sticas')\n",
    "    axes[1,0].set_ylabel('Importancia Acumulada')\n",
    "    axes[1,0].set_title('Importancia Acumulada de Caracter√≠sticas')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Top vs Bottom features\n",
    "    top_5 = explainability_analysis['global_importance'].head(5)\n",
    "    bottom_5 = explainability_analysis['global_importance'].tail(5)\n",
    "    \n",
    "    # Crear comparaci√≥n\n",
    "    comparison_features = list(top_5['feature']) + list(bottom_5['feature'])\n",
    "    comparison_values = list(top_5['importance']) + list(bottom_5['importance'])\n",
    "    colors = ['darkgreen'] * 5 + ['darkred'] * 5\n",
    "    \n",
    "    axes[1,1].barh(range(len(comparison_features)), comparison_values, color=colors, alpha=0.7)\n",
    "    axes[1,1].set_yticks(range(len(comparison_features)))\n",
    "    axes[1,1].set_yticklabels(comparison_features)\n",
    "    axes[1,1].set_xlabel('Importancia')\n",
    "    axes[1,1].set_title('Top 5 vs Bottom 5 Caracter√≠sticas')\n",
    "    axes[1,1].invert_yaxis()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('explainability_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ An√°lisis de explicabilidad guardado como 'explainability_analysis.png'\")\n",
    "    \n",
    "    # Mostrar estad√≠sticas de explicabilidad\n",
    "    print(f\"\\nüìä ESTAD√çSTICAS DE EXPLICABILIDAD:\")\n",
    "    print(f\"  Top 5 caracter√≠sticas explican: {cumulative_importance.iloc[4]:.1%} de la importancia\")\n",
    "    print(f\"  Top 10 caracter√≠sticas explican: {cumulative_importance.iloc[9]:.1%} de la importancia\")\n",
    "    print(f\"  Caracter√≠sticas para 80% importancia: {(cumulative_importance >= 0.8).idxmax() + 1}\")\n",
    "    print(f\"  Caracter√≠sticas para 90% importancia: {(cumulative_importance >= 0.9).idxmax() + 1}\")\n",
    "    \n",
    "    # Guardar top features para an√°lisis posterior\n",
    "    top_important_features = explainability_analysis['global_importance'].head(10)['feature'].tolist()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No se pudo completar el an√°lisis de explicabilidad\")\n",
    "    top_important_features = feature_names[:10]  # Fallback\n",
    "\n",
    "print(f\"\\nüìã TOP 10 CARACTER√çSTICAS M√ÅS EXPLICATIVAS:\")\n",
    "for i, feature in enumerate(top_important_features, 1):\n",
    "    importance_val = explainability_analysis['global_importance'][\n",
    "        explainability_analysis['global_importance']['feature'] == feature\n",
    "    ]['importance'].iloc[0]\n",
    "    print(f\"  {i:2d}. {feature:30s} (importancia: {importance_val:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. AN√ÅLISIS DE EQUIDAD Y SESGO\n",
    "print(\"\\n‚öñÔ∏è AN√ÅLISIS DE EQUIDAD Y SESGO DEL MODELO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def analyze_fairness_and_bias(X_data, y_true, y_pred, y_proba, feature_names):\n",
    "    \"\"\"Analiza equidad y sesgo en las predicciones del modelo\"\"\"\n",
    "    \n",
    "    fairness_results = {}\n",
    "    \n",
    "    # 1. An√°lisis de disparidad en caracter√≠sticas t√©cnicas vs no t√©cnicas\n",
    "    print(\"üìä An√°lisis de disparidad por tipo de caracter√≠sticas...\")\n",
    "    \n",
    "    # Identificar caracter√≠sticas t√©cnicas vs demogr√°ficas/blandas\n",
    "    technical_features = []\n",
    "    soft_features = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        feature_lower = feature.lower()\n",
    "        if any(tech_word in feature_lower for tech_word in \n",
    "               ['skill', 'experience', 'years', 'certification', 'degree', 'technical', 'programming', 'software']):\n",
    "            technical_features.append(feature)\n",
    "        else:\n",
    "            soft_features.append(feature)\n",
    "    \n",
    "    print(f\"  Caracter√≠sticas t√©cnicas: {len(technical_features)}\")\n",
    "    print(f\"  Caracter√≠sticas no t√©cnicas: {len(soft_features)}\")\n",
    "    \n",
    "    # 2. An√°lisis de correlaci√≥n entre caracter√≠sticas y predicciones\n",
    "    correlation_analysis = {}\n",
    "    \n",
    "    # Calcular correlaciones significativas\n",
    "    for feature in feature_names:\n",
    "        if feature in X_data.columns:\n",
    "            # Correlaci√≥n con predicci√≥n\n",
    "            corr_pred = np.corrcoef(X_data[feature], y_pred)[0,1]\n",
    "            # Correlaci√≥n con probabilidad\n",
    "            corr_proba = np.corrcoef(X_data[feature], y_proba)[0,1]\n",
    "            # Correlaci√≥n con truth\n",
    "            corr_truth = np.corrcoef(X_data[feature], y_true)[0,1]\n",
    "            \n",
    "            correlation_analysis[feature] = {\n",
    "                'corr_prediction': corr_pred if not np.isnan(corr_pred) else 0,\n",
    "                'corr_probability': corr_proba if not np.isnan(corr_proba) else 0,\n",
    "                'corr_truth': corr_truth if not np.isnan(corr_truth) else 0\n",
    "            }\n",
    "    \n",
    "    fairness_results['correlation_analysis'] = correlation_analysis\n",
    "    \n",
    "    # 3. An√°lisis de distribuci√≥n de probabilidades por cuartiles de caracter√≠sticas importantes\n",
    "    print(\"üìà An√°lisis de distribuci√≥n por cuartiles...\")\n",
    "    \n",
    "    quartile_analysis = {}\n",
    "    for feature in top_important_features[:5]:  # Top 5 caracter√≠sticas\n",
    "        if feature in X_data.columns:\n",
    "            # Dividir en cuartiles\n",
    "            quartiles = pd.qcut(X_data[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "            \n",
    "            quartile_stats = {}\n",
    "            for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "                mask = (quartiles == q)\n",
    "                if mask.sum() > 0:\n",
    "                    quartile_stats[q] = {\n",
    "                        'count': mask.sum(),\n",
    "                        'positive_rate': y_true[mask].mean(),\n",
    "                        'predicted_positive_rate': y_pred[mask].mean(),\n",
    "                        'mean_probability': y_proba[mask].mean(),\n",
    "                        'std_probability': y_proba[mask].std()\n",
    "                    }\n",
    "            \n",
    "            quartile_analysis[feature] = quartile_stats\n",
    "    \n",
    "    fairness_results['quartile_analysis'] = quartile_analysis\n",
    "    \n",
    "    # 4. An√°lisis de paridad demogr√°fica simulada\n",
    "    print(\"üéØ An√°lisis de paridad demogr√°fica...\")\n",
    "    \n",
    "    # Crear grupos sint√©ticos basados en caracter√≠sticas del modelo\n",
    "    # Grupo 1: Alta experiencia + alta educaci√≥n\n",
    "    # Grupo 2: Experiencia media\n",
    "    # Grupo 3: Baja experiencia\n",
    "    \n",
    "    demographic_parity = {}\n",
    "    \n",
    "    # Identificar features relacionadas con experiencia y educaci√≥n\n",
    "    experience_features = [f for f in feature_names if 'experience' in f.lower() or 'years' in f.lower()]\n",
    "    education_features = [f for f in feature_names if 'education' in f.lower() or 'degree' in f.lower()]\n",
    "    \n",
    "    if experience_features and education_features:\n",
    "        # Crear score compuesto\n",
    "        exp_score = X_data[experience_features].mean(axis=1) if len(experience_features) > 1 else X_data[experience_features[0]]\n",
    "        edu_score = X_data[education_features].mean(axis=1) if len(education_features) > 1 else X_data[education_features[0]]\n",
    "        \n",
    "        # Crear grupos basados en terciles\n",
    "        exp_terciles = pd.qcut(exp_score, q=3, labels=['Low_Exp', 'Mid_Exp', 'High_Exp'], duplicates='drop')\n",
    "        edu_terciles = pd.qcut(edu_score, q=3, labels=['Low_Edu', 'Mid_Edu', 'High_Edu'], duplicates='drop')\n",
    "        \n",
    "        # Analizar paridad entre grupos\n",
    "        for exp_group in ['Low_Exp', 'Mid_Exp', 'High_Exp']:\n",
    "            for edu_group in ['Low_Edu', 'Mid_Edu', 'High_Edu']:\n",
    "                group_mask = (exp_terciles == exp_group) & (edu_terciles == edu_group)\n",
    "                if group_mask.sum() > 10:  # Solo grupos con suficientes muestras\n",
    "                    group_name = f\"{exp_group}_{edu_group}\"\n",
    "                    demographic_parity[group_name] = {\n",
    "                        'count': group_mask.sum(),\n",
    "                        'positive_rate': y_true[group_mask].mean(),\n",
    "                        'predicted_positive_rate': y_pred[group_mask].mean(),\n",
    "                        'mean_probability': y_proba[group_mask].mean(),\n",
    "                        'false_positive_rate': ((y_pred[group_mask] == 1) & (y_true[group_mask] == 0)).sum() / max(1, (y_true[group_mask] == 0).sum()),\n",
    "                        'false_negative_rate': ((y_pred[group_mask] == 0) & (y_true[group_mask] == 1)).sum() / max(1, (y_true[group_mask] == 1).sum())\n",
    "                    }\n",
    "    \n",
    "    fairness_results['demographic_parity'] = demographic_parity\n",
    "    \n",
    "    # 5. M√©tricas de equidad\n",
    "    equity_metrics = {}\n",
    "    \n",
    "    # Calcular m√©tricas de equidad entre grupos\n",
    "    if demographic_parity:\n",
    "        positive_rates = [group['predicted_positive_rate'] for group in demographic_parity.values()]\n",
    "        fpr_rates = [group['false_positive_rate'] for group in demographic_parity.values()]\n",
    "        fnr_rates = [group['false_negative_rate'] for group in demographic_parity.values()]\n",
    "        \n",
    "        equity_metrics = {\n",
    "            'demographic_parity_difference': max(positive_rates) - min(positive_rates),\n",
    "            'equalized_odds_difference_fpr': max(fpr_rates) - min(fpr_rates),\n",
    "            'equalized_odds_difference_fnr': max(fnr_rates) - min(fnr_rates),\n",
    "            'statistical_parity_ratio': min(positive_rates) / max(positive_rates) if max(positive_rates) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    fairness_results['equity_metrics'] = equity_metrics\n",
    "    fairness_results['technical_features'] = technical_features\n",
    "    fairness_results['soft_features'] = soft_features\n",
    "    \n",
    "    return fairness_results\n",
    "\n",
    "# Realizar an√°lisis de equidad\n",
    "fairness_analysis = analyze_fairness_and_bias(\n",
    "    X_combined, y_combined_true, y_combined_pred, y_combined_proba, feature_names\n",
    ")\n",
    "\n",
    "# Visualizar an√°lisis de equidad\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# 1. Correlaciones features-predicci√≥n\n",
    "if 'correlation_analysis' in fairness_analysis:\n",
    "    corr_data = fairness_analysis['correlation_analysis']\n",
    "    features = list(corr_data.keys())[:15]  # Top 15\n",
    "    pred_corrs = [corr_data[f]['corr_prediction'] for f in features]\n",
    "    \n",
    "    axes[plot_idx].barh(range(len(features)), pred_corrs)\n",
    "    axes[plot_idx].set_yticks(range(len(features)))\n",
    "    axes[plot_idx].set_yticklabels(features)\n",
    "    axes[plot_idx].set_xlabel('Correlaci√≥n con Predicci√≥n')\n",
    "    axes[plot_idx].set_title('Correlaci√≥n Features-Predicci√≥n')\n",
    "    axes[plot_idx].invert_yaxis()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 2. Distribuci√≥n por cuartiles de feature m√°s importante\n",
    "if 'quartile_analysis' in fairness_analysis and fairness_analysis['quartile_analysis']:\n",
    "    top_feature = list(fairness_analysis['quartile_analysis'].keys())[0]\n",
    "    quartile_data = fairness_analysis['quartile_analysis'][top_feature]\n",
    "    \n",
    "    quartiles = list(quartile_data.keys())\n",
    "    true_rates = [quartile_data[q]['positive_rate'] for q in quartiles]\n",
    "    pred_rates = [quartile_data[q]['predicted_positive_rate'] for q in quartiles]\n",
    "    \n",
    "    x = np.arange(len(quartiles))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[plot_idx].bar(x - width/2, true_rates, width, label='Tasa Real', alpha=0.8)\n",
    "    axes[plot_idx].bar(x + width/2, pred_rates, width, label='Tasa Predicha', alpha=0.8)\n",
    "    axes[plot_idx].set_xlabel('Cuartil')\n",
    "    axes[plot_idx].set_ylabel('Tasa Positiva')\n",
    "    axes[plot_idx].set_title(f'Tasas por Cuartil - {top_feature}')\n",
    "    axes[plot_idx].set_xticks(x)\n",
    "    axes[plot_idx].set_xticklabels(quartiles)\n",
    "    axes[plot_idx].legend()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 3. Paridad demogr√°fica\n",
    "if 'demographic_parity' in fairness_analysis and fairness_analysis['demographic_parity']:\n",
    "    parity_data = fairness_analysis['demographic_parity']\n",
    "    groups = list(parity_data.keys())\n",
    "    positive_rates = [parity_data[g]['predicted_positive_rate'] for g in groups]\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(groups)))\n",
    "    axes[plot_idx].bar(range(len(groups)), positive_rates, color=colors, alpha=0.8)\n",
    "    axes[plot_idx].set_xlabel('Grupo Demogr√°fico')\n",
    "    axes[plot_idx].set_ylabel('Tasa Positiva Predicha')\n",
    "    axes[plot_idx].set_title('Paridad Demogr√°fica por Grupos')\n",
    "    axes[plot_idx].set_xticks(range(len(groups)))\n",
    "    axes[plot_idx].set_xticklabels(groups, rotation=45, ha='right')\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 4. M√©tricas de equidad\n",
    "if 'equity_metrics' in fairness_analysis and fairness_analysis['equity_metrics']:\n",
    "    equity_data = fairness_analysis['equity_metrics']\n",
    "    metrics = list(equity_data.keys())\n",
    "    values = list(equity_data.values())\n",
    "    \n",
    "    colors = ['red' if abs(v) > 0.1 else 'green' for v in values]\n",
    "    axes[plot_idx].bar(range(len(metrics)), values, color=colors, alpha=0.7)\n",
    "    axes[plot_idx].set_xlabel('M√©trica de Equidad')\n",
    "    axes[plot_idx].set_ylabel('Valor')\n",
    "    axes[plot_idx].set_title('M√©tricas de Equidad\\n(Verde: Bueno, Rojo: Problem√°tico)')\n",
    "    axes[plot_idx].set_xticks(range(len(metrics)))\n",
    "    axes[plot_idx].set_xticklabels([m.replace('_', '\\n') for m in metrics], rotation=45, ha='right')\n",
    "    axes[plot_idx].axhline(y=0.1, color='orange', linestyle='--', alpha=0.7, label='Umbral preocupante')\n",
    "    axes[plot_idx].axhline(y=-0.1, color='orange', linestyle='--', alpha=0.7)\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 5. Distribuci√≥n de caracter√≠sticas t√©cnicas vs no t√©cnicas\n",
    "tech_features = fairness_analysis.get('technical_features', [])\n",
    "soft_features = fairness_analysis.get('soft_features', [])\n",
    "\n",
    "categories = ['T√©cnicas', 'No T√©cnicas']\n",
    "counts = [len(tech_features), len(soft_features)]\n",
    "\n",
    "axes[plot_idx].pie(counts, labels=categories, autopct='%1.1f%%', startangle=90)\n",
    "axes[plot_idx].set_title('Distribuci√≥n de Tipos de Caracter√≠sticas')\n",
    "plot_idx += 1\n",
    "\n",
    "# 6. An√°lisis de sesgo en probabilidades\n",
    "prob_bins = np.linspace(0, 1, 11)\n",
    "prob_centers = (prob_bins[:-1] + prob_bins[1:]) / 2\n",
    "\n",
    "# Calcular precisi√≥n por bin de probabilidad\n",
    "precision_by_prob = []\n",
    "for i in range(len(prob_bins)-1):\n",
    "    mask = (y_combined_proba >= prob_bins[i]) & (y_combined_proba < prob_bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        precision = y_combined_true[mask].mean()\n",
    "        precision_by_prob.append(precision)\n",
    "    else:\n",
    "        precision_by_prob.append(0)\n",
    "\n",
    "axes[plot_idx].plot(prob_centers, precision_by_prob, 'bo-', linewidth=2, markersize=6)\n",
    "axes[plot_idx].plot([0, 1], [0, 1], 'r--', alpha=0.7, label='Perfecta calibraci√≥n')\n",
    "axes[plot_idx].set_xlabel('Probabilidad Predicha')\n",
    "axes[plot_idx].set_ylabel('Precisi√≥n Real')\n",
    "axes[plot_idx].set_title('Calibraci√≥n del Modelo')\n",
    "axes[plot_idx].legend()\n",
    "axes[plot_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fairness_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ An√°lisis de equidad guardado como 'fairness_analysis.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. AN√ÅLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "print(\"\\nüõ°Ô∏è AN√ÅLISIS DE ROBUSTEZ Y ESTABILIDAD DEL MODELO\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "def analyze_model_robustness(model, X_data, y_true, feature_names):\n",
    "    \"\"\"Analiza la robustez y estabilidad del modelo\"\"\"\n",
    "    \n",
    "    robustness_results = {}\n",
    "    \n",
    "    # 1. An√°lisis de estabilidad con muestreo bootstrap\n",
    "    print(\"üìä An√°lisis de estabilidad con bootstrap...\")\n",
    "    \n",
    "    n_bootstrap = 100\n",
    "    bootstrap_metrics = []\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Crear muestra bootstrap\n",
    "        indices = np.random.choice(len(X_data), size=len(X_data), replace=True)\n",
    "        X_boot = X_data.iloc[indices]\n",
    "        y_boot = y_true.iloc[indices]\n",
    "        \n",
    "        # Predecir con el modelo\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_boot)[:, 1]\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        else:\n",
    "            y_pred = model.predict(X_boot)\n",
    "            y_pred_proba = y_pred  # Para modelos sin probabilidades\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        accuracy = (y_pred == y_boot).mean()\n",
    "        \n",
    "        if len(np.unique(y_boot)) > 1 and len(np.unique(y_pred)) > 1:\n",
    "            from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "            f1 = f1_score(y_boot, y_pred, average='macro')\n",
    "            precision = precision_score(y_boot, y_pred, average='macro')\n",
    "            recall = recall_score(y_boot, y_pred, average='macro')\n",
    "        else:\n",
    "            f1 = precision = recall = 0\n",
    "        \n",
    "        bootstrap_metrics.append({\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        })\n",
    "    \n",
    "    # Calcular estad√≠sticas de estabilidad\n",
    "    bootstrap_df = pd.DataFrame(bootstrap_metrics)\n",
    "    stability_stats = {\n",
    "        'accuracy_mean': bootstrap_df['accuracy'].mean(),\n",
    "        'accuracy_std': bootstrap_df['accuracy'].std(),\n",
    "        'accuracy_cv': bootstrap_df['accuracy'].std() / bootstrap_df['accuracy'].mean(),\n",
    "        'f1_mean': bootstrap_df['f1_score'].mean(),\n",
    "        'f1_std': bootstrap_df['f1_score'].std(),\n",
    "        'f1_cv': bootstrap_df['f1_score'].std() / max(bootstrap_df['f1_score'].mean(), 0.001)\n",
    "    }\n",
    "    \n",
    "    robustness_results['bootstrap_stability'] = stability_stats\n",
    "    robustness_results['bootstrap_metrics'] = bootstrap_df\n",
    "    \n",
    "    print(f\"  Estabilidad de accuracy: CV = {stability_stats['accuracy_cv']:.3f}\")\n",
    "    print(f\"  Estabilidad de F1: CV = {stability_stats['f1_cv']:.3f}\")\n",
    "    \n",
    "    # 2. An√°lisis de sensibilidad a perturbaciones\n",
    "    print(\"üîÄ An√°lisis de sensibilidad a perturbaciones...\")\n",
    "    \n",
    "    perturbation_results = {}\n",
    "    noise_levels = [0.01, 0.05, 0.1, 0.2]\n",
    "    \n",
    "    # Predicci√≥n baseline\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        baseline_pred = model.predict_proba(X_data)[:, 1]\n",
    "    else:\n",
    "        baseline_pred = model.predict(X_data)\n",
    "    \n",
    "    for noise_level in noise_levels:\n",
    "        # Agregar ruido gaussiano\n",
    "        X_noisy = X_data.copy()\n",
    "        for col in X_data.columns:\n",
    "            if X_data[col].dtype in ['float64', 'int64']:\n",
    "                noise = np.random.normal(0, noise_level * X_data[col].std(), len(X_data))\n",
    "                X_noisy[col] = X_data[col] + noise\n",
    "        \n",
    "        # Predecir con datos ruidosos\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            noisy_pred = model.predict_proba(X_noisy)[:, 1]\n",
    "        else:\n",
    "            noisy_pred = model.predict(X_noisy)\n",
    "        \n",
    "        # Calcular diferencia\n",
    "        pred_diff = np.abs(noisy_pred - baseline_pred).mean()\n",
    "        pred_correlation = np.corrcoef(baseline_pred, noisy_pred)[0, 1]\n",
    "        \n",
    "        perturbation_results[noise_level] = {\n",
    "            'mean_prediction_difference': pred_diff,\n",
    "            'prediction_correlation': pred_correlation\n",
    "        }\n",
    "    \n",
    "    robustness_results['perturbation_analysis'] = perturbation_results\n",
    "    \n",
    "    # 3. An√°lisis de caracter√≠sticas influyentes\n",
    "    print(\"üéØ An√°lisis de caracter√≠sticas m√°s influyentes...\")\n",
    "    \n",
    "    feature_influence = {}\n",
    "    sample_size = min(200, len(X_data))\n",
    "    X_sample = X_data.sample(sample_size, random_state=42)\n",
    "    \n",
    "    baseline_sample_pred = model.predict_proba(X_sample)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_sample)\n",
    "    \n",
    "    for feature in feature_names[:10]:  # Top 10 features m√°s importantes\n",
    "        if feature in X_sample.columns:\n",
    "            # Perturbar solo esta feature\n",
    "            X_perturbed = X_sample.copy()\n",
    "            \n",
    "            if X_sample[feature].dtype in ['float64', 'int64']:\n",
    "                # Para features num√©ricas, agregar ruido\n",
    "                X_perturbed[feature] = X_sample[feature] + np.random.normal(0, X_sample[feature].std() * 0.1, sample_size)\n",
    "            else:\n",
    "                # Para features categ√≥ricas, shuffle\n",
    "                X_perturbed[feature] = np.random.permutation(X_sample[feature])\n",
    "            \n",
    "            # Predecir con feature perturbada\n",
    "            perturbed_pred = model.predict_proba(X_perturbed)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_perturbed)\n",
    "            \n",
    "            # Calcular influencia\n",
    "            influence = np.abs(perturbed_pred - baseline_sample_pred).mean()\n",
    "            feature_influence[feature] = influence\n",
    "    \n",
    "    robustness_results['feature_influence'] = feature_influence\n",
    "    \n",
    "    # 4. An√°lisis de casos l√≠mite\n",
    "    print(\"üîç An√°lisis de casos l√≠mite...\")\n",
    "    \n",
    "    edge_case_analysis = {}\n",
    "    \n",
    "    # Casos con probabilidades cerca del umbral de decisi√≥n\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(X_data)[:, 1]\n",
    "        \n",
    "        # Casos cerca del umbral (0.4-0.6)\n",
    "        near_threshold = np.abs(probabilities - 0.5) < 0.1\n",
    "        edge_case_analysis['near_threshold_count'] = near_threshold.sum()\n",
    "        edge_case_analysis['near_threshold_percentage'] = near_threshold.mean()\n",
    "        \n",
    "        # Casos con alta confianza pero incorrectos\n",
    "        high_confidence = np.abs(probabilities - 0.5) > 0.4\n",
    "        if len(y_true) == len(probabilities):\n",
    "            predictions = (probabilities > 0.5).astype(int)\n",
    "            incorrect = predictions != y_true\n",
    "            high_conf_incorrect = high_confidence & incorrect\n",
    "            edge_case_analysis['high_confidence_errors'] = high_conf_incorrect.sum()\n",
    "            edge_case_analysis['high_confidence_error_rate'] = high_conf_incorrect.mean()\n",
    "    \n",
    "    robustness_results['edge_case_analysis'] = edge_case_analysis\n",
    "    \n",
    "    return robustness_results\n",
    "\n",
    "# Realizar an√°lisis de robustez\n",
    "robustness_analysis = analyze_model_robustness(\n",
    "    model, X_combined, y_combined_true, feature_names\n",
    ")\n",
    "\n",
    "# Visualizar an√°lisis de robustez\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# 1. Distribuci√≥n de m√©tricas bootstrap\n",
    "if 'bootstrap_metrics' in robustness_analysis:\n",
    "    bootstrap_df = robustness_analysis['bootstrap_metrics']\n",
    "    \n",
    "    axes[plot_idx].hist(bootstrap_df['accuracy'], bins=20, alpha=0.7, label='Accuracy', density=True)\n",
    "    axes[plot_idx].hist(bootstrap_df['f1_score'], bins=20, alpha=0.7, label='F1-Score', density=True)\n",
    "    axes[plot_idx].set_xlabel('Valor de M√©trica')\n",
    "    axes[plot_idx].set_ylabel('Densidad')\n",
    "    axes[plot_idx].set_title('Distribuci√≥n de M√©tricas\\n(Bootstrap Stability)')\n",
    "    axes[plot_idx].legend()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 2. Coeficiente de variaci√≥n de m√©tricas\n",
    "if 'bootstrap_stability' in robustness_analysis:\n",
    "    stability_data = robustness_analysis['bootstrap_stability']\n",
    "    metrics = ['accuracy_cv', 'f1_cv']\n",
    "    cv_values = [stability_data[m] for m in metrics]\n",
    "    \n",
    "    colors = ['green' if cv < 0.05 else 'orange' if cv < 0.1 else 'red' for cv in cv_values]\n",
    "    \n",
    "    axes[plot_idx].bar(range(len(metrics)), cv_values, color=colors, alpha=0.7)\n",
    "    axes[plot_idx].set_xlabel('M√©trica')\n",
    "    axes[plot_idx].set_ylabel('Coeficiente de Variaci√≥n')\n",
    "    axes[plot_idx].set_title('Estabilidad del Modelo\\n(Verde: Estable, Rojo: Inestable)')\n",
    "    axes[plot_idx].set_xticks(range(len(metrics)))\n",
    "    axes[plot_idx].set_xticklabels(['Accuracy CV', 'F1 CV'])\n",
    "    axes[plot_idx].axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, label='Umbral aceptable')\n",
    "    axes[plot_idx].axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='Umbral problem√°tico')\n",
    "    axes[plot_idx].legend()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 3. Sensibilidad a perturbaciones\n",
    "if 'perturbation_analysis' in robustness_analysis:\n",
    "    pert_data = robustness_analysis['perturbation_analysis']\n",
    "    noise_levels = list(pert_data.keys())\n",
    "    pred_diffs = [pert_data[level]['mean_prediction_difference'] for level in noise_levels]\n",
    "    correlations = [pert_data[level]['prediction_correlation'] for level in noise_levels]\n",
    "    \n",
    "    axes[plot_idx].plot(noise_levels, pred_diffs, 'ro-', linewidth=2, label='Diferencia Media')\n",
    "    axes[plot_idx].set_xlabel('Nivel de Ruido')\n",
    "    axes[plot_idx].set_ylabel('Diferencia en Predicciones')\n",
    "    axes[plot_idx].set_title('Sensibilidad a Perturbaciones')\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 4. Correlaci√≥n con perturbaciones\n",
    "axes[plot_idx].plot(noise_levels, correlations, 'bo-', linewidth=2, label='Correlaci√≥n')\n",
    "axes[plot_idx].set_xlabel('Nivel de Ruido')\n",
    "axes[plot_idx].set_ylabel('Correlaci√≥n con Baseline')\n",
    "axes[plot_idx].set_title('Correlaci√≥n bajo Perturbaciones')\n",
    "axes[plot_idx].set_ylim([0, 1])\n",
    "axes[plot_idx].grid(True, alpha=0.3)\n",
    "plot_idx += 1\n",
    "\n",
    "# 5. Influencia de caracter√≠sticas\n",
    "if 'feature_influence' in robustness_analysis:\n",
    "    influence_data = robustness_analysis['feature_influence']\n",
    "    features = list(influence_data.keys())\n",
    "    influences = list(influence_data.values())\n",
    "    \n",
    "    axes[plot_idx].barh(range(len(features)), influences)\n",
    "    axes[plot_idx].set_yticks(range(len(features)))\n",
    "    axes[plot_idx].set_yticklabels(features)\n",
    "    axes[plot_idx].set_xlabel('Influencia (Diferencia Media)')\n",
    "    axes[plot_idx].set_title('Influencia por Caracter√≠stica')\n",
    "    axes[plot_idx].invert_yaxis()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 6. An√°lisis de casos l√≠mite\n",
    "if 'edge_case_analysis' in robustness_analysis:\n",
    "    edge_data = robustness_analysis['edge_case_analysis']\n",
    "    \n",
    "    categories = []\n",
    "    values = []\n",
    "    \n",
    "    if 'near_threshold_percentage' in edge_data:\n",
    "        categories.append('Cerca del\\nUmbral')\n",
    "        values.append(edge_data['near_threshold_percentage'] * 100)\n",
    "    \n",
    "    if 'high_confidence_error_rate' in edge_data:\n",
    "        categories.append('Errores Alta\\nConfianza')\n",
    "        values.append(edge_data['high_confidence_error_rate'] * 100)\n",
    "    \n",
    "    if categories:\n",
    "        colors = ['orange', 'red'][:len(categories)]\n",
    "        axes[plot_idx].bar(range(len(categories)), values, color=colors, alpha=0.7)\n",
    "        axes[plot_idx].set_xlabel('Tipo de Caso L√≠mite')\n",
    "        axes[plot_idx].set_ylabel('Porcentaje (%)')\n",
    "        axes[plot_idx].set_title('An√°lisis de Casos L√≠mite')\n",
    "        axes[plot_idx].set_xticks(range(len(categories)))\n",
    "        axes[plot_idx].set_xticklabels(categories)\n",
    "        axes[plot_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('robustness_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ An√°lisis de robustez guardado como 'robustness_analysis.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. REPORTE EJECUTIVO DE INTELIGENCIA ARTIFICIAL RESPONSABLE\n",
    "print(\"\\nüìã REPORTE EJECUTIVO - RAI DASHBOARD\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "def generate_rai_executive_report(explainability_analysis, fairness_analysis, robustness_analysis, model_info):\n",
    "    \"\"\"Genera un reporte ejecutivo completo de RAI\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'model_info': model_info,\n",
    "        'executive_summary': {},\n",
    "        'detailed_findings': {},\n",
    "        'recommendations': [],\n",
    "        'risk_assessment': {},\n",
    "        'compliance_score': {}\n",
    "    }\n",
    "    \n",
    "    # 1. RESUMEN EJECUTIVO\n",
    "    print(\"üìä Generando resumen ejecutivo...\")\n",
    "    \n",
    "    # Explicabilidad\n",
    "    explainability_score = 0\n",
    "    if 'global_importance' in explainability_analysis:\n",
    "        # Score basado en concentraci√≥n de importancia\n",
    "        importance_df = explainability_analysis['global_importance']\n",
    "        top_5_importance = importance_df.head(5)['importance'].sum()\n",
    "        total_importance = importance_df['importance'].sum()\n",
    "        concentration_ratio = top_5_importance / total_importance if total_importance > 0 else 0\n",
    "        \n",
    "        if concentration_ratio > 0.8:\n",
    "            explainability_score = 85  # Muy concentrado, f√°cil explicar\n",
    "        elif concentration_ratio > 0.6:\n",
    "            explainability_score = 70  # Moderadamente concentrado\n",
    "        else:\n",
    "            explainability_score = 50  # Muy distribuido, dif√≠cil explicar\n",
    "    \n",
    "    # Equidad\n",
    "    fairness_score = 90  # Baseline alto\n",
    "    if 'equity_metrics' in fairness_analysis and fairness_analysis['equity_metrics']:\n",
    "        equity_metrics = fairness_analysis['equity_metrics']\n",
    "        \n",
    "        for metric, value in equity_metrics.items():\n",
    "            if abs(value) > 0.2:\n",
    "                fairness_score -= 30\n",
    "            elif abs(value) > 0.1:\n",
    "                fairness_score -= 15\n",
    "            elif abs(value) > 0.05:\n",
    "                fairness_score -= 5\n",
    "    \n",
    "    # Robustez\n",
    "    robustness_score = 80  # Baseline\n",
    "    if 'bootstrap_stability' in robustness_analysis:\n",
    "        stability_stats = robustness_analysis['bootstrap_stability']\n",
    "        \n",
    "        # Penalizar alta variabilidad\n",
    "        if stability_stats['accuracy_cv'] > 0.1:\n",
    "            robustness_score -= 30\n",
    "        elif stability_stats['accuracy_cv'] > 0.05:\n",
    "            robustness_score -= 15\n",
    "        \n",
    "        if stability_stats['f1_cv'] > 0.1:\n",
    "            robustness_score -= 20\n",
    "        elif stability_stats['f1_cv'] > 0.05:\n",
    "            robustness_score -= 10\n",
    "    \n",
    "    # Score general RAI\n",
    "    overall_rai_score = (explainability_score + fairness_score + robustness_score) / 3\n",
    "    \n",
    "    report['executive_summary'] = {\n",
    "        'overall_rai_score': overall_rai_score,\n",
    "        'explainability_score': explainability_score,\n",
    "        'fairness_score': fairness_score,\n",
    "        'robustness_score': robustness_score,\n",
    "        'rai_level': 'EXCELENTE' if overall_rai_score >= 80 else 'BUENO' if overall_rai_score >= 65 else 'ACEPTABLE' if overall_rai_score >= 50 else 'REQUIERE MEJORAS'\n",
    "    }\n",
    "    \n",
    "    # 2. HALLAZGOS DETALLADOS\n",
    "    detailed_findings = {}\n",
    "    \n",
    "    # Explicabilidad\n",
    "    if 'global_importance' in explainability_analysis:\n",
    "        importance_df = explainability_analysis['global_importance']\n",
    "        detailed_findings['explainability'] = {\n",
    "            'top_3_features': importance_df.head(3)['feature'].tolist(),\n",
    "            'features_for_80_percent': len(importance_df[importance_df['importance'].cumsum() / importance_df['importance'].sum() <= 0.8]),\n",
    "            'importance_concentration': concentration_ratio\n",
    "        }\n",
    "    \n",
    "    # Equidad\n",
    "    if 'demographic_parity' in fairness_analysis and fairness_analysis['demographic_parity']:\n",
    "        parity_data = fairness_analysis['demographic_parity']\n",
    "        positive_rates = [group['predicted_positive_rate'] for group in parity_data.values()]\n",
    "        detailed_findings['fairness'] = {\n",
    "            'max_group_disparity': max(positive_rates) - min(positive_rates),\n",
    "            'number_of_groups_analyzed': len(parity_data),\n",
    "            'groups_with_high_disparity': sum(1 for group in parity_data.values() if abs(group['predicted_positive_rate'] - np.mean(positive_rates)) > 0.1)\n",
    "        }\n",
    "    \n",
    "    # Robustez\n",
    "    if 'bootstrap_stability' in robustness_analysis:\n",
    "        stability_stats = robustness_analysis['bootstrap_stability']\n",
    "        detailed_findings['robustness'] = {\n",
    "            'accuracy_stability_cv': stability_stats['accuracy_cv'],\n",
    "            'f1_stability_cv': stability_stats['f1_cv'],\n",
    "            'model_stability_level': 'ALTA' if max(stability_stats['accuracy_cv'], stability_stats['f1_cv']) < 0.05 else 'MEDIA' if max(stability_stats['accuracy_cv'], stability_stats['f1_cv']) < 0.1 else 'BAJA'\n",
    "        }\n",
    "    \n",
    "    report['detailed_findings'] = detailed_findings\n",
    "    \n",
    "    # 3. RECOMENDACIONES\n",
    "    recommendations = []\n",
    "    \n",
    "    # Recomendaciones de explicabilidad\n",
    "    if explainability_score < 70:\n",
    "        recommendations.append({\n",
    "            'category': 'Explicabilidad',\n",
    "            'priority': 'ALTA',\n",
    "            'recommendation': 'Simplificar el modelo o implementar t√©cnicas de interpretabilidad local para mejorar la explicabilidad',\n",
    "            'action_items': ['Implementar LIME o SHAP para explicaciones locales', 'Considerar modelos m√°s simples', 'Documentar las caracter√≠sticas m√°s importantes']\n",
    "        })\n",
    "    \n",
    "    # Recomendaciones de equidad\n",
    "    if fairness_score < 70:\n",
    "        recommendations.append({\n",
    "            'category': 'Equidad',\n",
    "            'priority': 'ALTA',\n",
    "            'recommendation': 'Abordar sesgos detectados en el modelo mediante t√©cnicas de mitigaci√≥n',\n",
    "            'action_items': ['Rebalancear datos de entrenamiento', 'Implementar restricciones de equidad', 'Monitorear m√©tricas de equidad en producci√≥n']\n",
    "        })\n",
    "    \n",
    "    # Recomendaciones de robustez\n",
    "    if robustness_score < 70:\n",
    "        recommendations.append({\n",
    "            'category': 'Robustez',\n",
    "            'priority': 'MEDIA',\n",
    "            'recommendation': 'Mejorar la estabilidad del modelo mediante t√©cnicas de regularizaci√≥n',\n",
    "            'action_items': ['Aumentar datos de entrenamiento', 'Aplicar t√©cnicas de regularizaci√≥n', 'Implementar validaci√≥n cruzada robusta']\n",
    "        })\n",
    "    \n",
    "    # Recomendaciones generales\n",
    "    if overall_rai_score >= 80:\n",
    "        recommendations.append({\n",
    "            'category': 'General',\n",
    "            'priority': 'BAJA',\n",
    "            'recommendation': 'Mantener monitoreo continuo y documentaci√≥n de RAI',\n",
    "            'action_items': ['Implementar monitoreo en tiempo real', 'Crear documentaci√≥n de RAI', 'Establecer revisiones peri√≥dicas']\n",
    "        })\n",
    "    \n",
    "    report['recommendations'] = recommendations\n",
    "    \n",
    "    # 4. EVALUACI√ìN DE RIESGOS\n",
    "    risk_level = 'BAJO'\n",
    "    risk_factors = []\n",
    "    \n",
    "    if explainability_score < 50:\n",
    "        risk_factors.append('Modelo dif√≠cil de explicar')\n",
    "        risk_level = 'ALTO'\n",
    "    elif explainability_score < 70:\n",
    "        risk_factors.append('Explicabilidad limitada')\n",
    "        if risk_level == 'BAJO':\n",
    "            risk_level = 'MEDIO'\n",
    "    \n",
    "    if fairness_score < 50:\n",
    "        risk_factors.append('Sesgos significativos detectados')\n",
    "        risk_level = 'ALTO'\n",
    "    elif fairness_score < 70:\n",
    "        risk_factors.append('Posibles sesgos menores')\n",
    "        if risk_level == 'BAJO':\n",
    "            risk_level = 'MEDIO'\n",
    "    \n",
    "    if robustness_score < 50:\n",
    "        risk_factors.append('Modelo inestable')\n",
    "        risk_level = 'ALTO'\n",
    "    elif robustness_score < 70:\n",
    "        risk_factors.append('Estabilidad moderada')\n",
    "        if risk_level == 'BAJO':\n",
    "            risk_level = 'MEDIO'\n",
    "    \n",
    "    report['risk_assessment'] = {\n",
    "        'overall_risk_level': risk_level,\n",
    "        'risk_factors': risk_factors,\n",
    "        'mitigation_priority': 'INMEDIATA' if risk_level == 'ALTO' else 'CORTO_PLAZO' if risk_level == 'MEDIO' else 'LARGO_PLAZO'\n",
    "    }\n",
    "    \n",
    "    # 5. PUNTUACI√ìN DE CUMPLIMIENTO\n",
    "    compliance_score = {\n",
    "        'gdpr_compliance': 85 if explainability_score > 70 else 60,  # Derecho a explicaci√≥n\n",
    "        'ai_ethics_score': overall_rai_score,\n",
    "        'regulatory_readiness': 90 if overall_rai_score > 75 and len(risk_factors) == 0 else 70 if overall_rai_score > 60 else 50\n",
    "    }\n",
    "    \n",
    "    report['compliance_score'] = compliance_score\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generar reporte RAI\n",
    "rai_report = generate_rai_executive_report(\n",
    "    explainability_analysis, \n",
    "    fairness_analysis, \n",
    "    robustness_analysis,\n",
    "    {\n",
    "        'model_name': training_info['best_model_name'],\n",
    "        'model_version': registered_model.version,\n",
    "        'feature_count': len(feature_names),\n",
    "        'training_samples': len(X_combined)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Visualizar dashboard ejecutivo RAI\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 1. Score general RAI\n",
    "scores = [\n",
    "    rai_report['executive_summary']['explainability_score'],\n",
    "    rai_report['executive_summary']['fairness_score'],\n",
    "    rai_report['executive_summary']['robustness_score'],\n",
    "    rai_report['executive_summary']['overall_rai_score']\n",
    "]\n",
    "labels = ['Explicabilidad', 'Equidad', 'Robustez', 'RAI General']\n",
    "colors = ['green' if s >= 80 else 'orange' if s >= 65 else 'red' for s in scores]\n",
    "\n",
    "axes[0].bar(range(len(labels)), scores, color=colors, alpha=0.8)\n",
    "axes[0].set_ylabel('Puntuaci√≥n')\n",
    "axes[0].set_title('Puntuaciones RAI')\n",
    "axes[0].set_xticks(range(len(labels)))\n",
    "axes[0].set_xticklabels(labels, rotation=45)\n",
    "axes[0].set_ylim([0, 100])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, score in enumerate(scores):\n",
    "    axes[0].text(i, score + 2, f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Nivel de riesgo\n",
    "risk_level = rai_report['risk_assessment']['overall_risk_level']\n",
    "risk_colors = {'BAJO': 'green', 'MEDIO': 'orange', 'ALTO': 'red'}\n",
    "risk_color = risk_colors.get(risk_level, 'gray')\n",
    "\n",
    "axes[1].pie([1], labels=[f'Riesgo\\n{risk_level}'], colors=[risk_color], autopct='', startangle=90)\n",
    "axes[1].set_title('Nivel de Riesgo General')\n",
    "\n",
    "# 3. Cumplimiento regulatorio\n",
    "compliance_data = rai_report['compliance_score']\n",
    "comp_labels = ['GDPR', '√âtica IA', 'Preparaci√≥n\\nRegulatoria']\n",
    "comp_values = [compliance_data['gdpr_compliance'], compliance_data['ai_ethics_score'], compliance_data['regulatory_readiness']]\n",
    "\n",
    "axes[2].bar(range(len(comp_labels)), comp_values, color=['blue', 'purple', 'teal'], alpha=0.7)\n",
    "axes[2].set_ylabel('Puntuaci√≥n')\n",
    "axes[2].set_title('Cumplimiento Regulatorio')\n",
    "axes[2].set_xticks(range(len(comp_labels)))\n",
    "axes[2].set_xticklabels(comp_labels)\n",
    "axes[2].set_ylim([0, 100])\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Top caracter√≠sticas m√°s importantes\n",
    "if 'explainability' in rai_report['detailed_findings']:\n",
    "    top_features = rai_report['detailed_findings']['explainability']['top_3_features']\n",
    "    axes[3].barh(range(len(top_features)), [3, 2, 1], color='lightblue', alpha=0.8)\n",
    "    axes[3].set_yticks(range(len(top_features)))\n",
    "    axes[3].set_yticklabels(top_features)\n",
    "    axes[3].set_xlabel('Ranking de Importancia')\n",
    "    axes[3].set_title('Top 3 Caracter√≠sticas\\nM√°s Importantes')\n",
    "    axes[3].invert_yaxis()\n",
    "\n",
    "# 5. Distribuci√≥n de recomendaciones por prioridad\n",
    "if rai_report['recommendations']:\n",
    "    priorities = [rec['priority'] for rec in rai_report['recommendations']]\n",
    "    priority_counts = pd.Series(priorities).value_counts()\n",
    "    \n",
    "    colors_priority = {'ALTA': 'red', 'MEDIA': 'orange', 'BAJA': 'green'}\n",
    "    colors = [colors_priority.get(p, 'gray') for p in priority_counts.index]\n",
    "    \n",
    "    axes[4].pie(priority_counts.values, labels=priority_counts.index, colors=colors, autopct='%1.0f', startangle=90)\n",
    "    axes[4].set_title('Distribuci√≥n de\\nRecomendaciones por Prioridad')\n",
    "\n",
    "# 6. Timeline de implementaci√≥n sugerido\n",
    "implementation_timeline = {\n",
    "    'Inmediato (0-1 mes)': len([r for r in rai_report['recommendations'] if r['priority'] == 'ALTA']),\n",
    "    'Corto plazo (1-3 meses)': len([r for r in rai_report['recommendations'] if r['priority'] == 'MEDIA']),\n",
    "    'Largo plazo (3+ meses)': len([r for r in rai_report['recommendations'] if r['priority'] == 'BAJA'])\n",
    "}\n",
    "\n",
    "timeline_labels = list(implementation_timeline.keys())\n",
    "timeline_values = list(implementation_timeline.values())\n",
    "\n",
    "axes[5].bar(range(len(timeline_labels)), timeline_values, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "axes[5].set_ylabel('N√∫mero de Acciones')\n",
    "axes[5].set_title('Timeline de Implementaci√≥n')\n",
    "axes[5].set_xticks(range(len(timeline_labels)))\n",
    "axes[5].set_xticklabels(timeline_labels, rotation=45, ha='right')\n",
    "\n",
    "# 7. Matriz de riesgo vs impacto\n",
    "risk_impact_data = []\n",
    "for rec in rai_report['recommendations']:\n",
    "    priority_to_risk = {'ALTA': 3, 'MEDIA': 2, 'BAJA': 1}\n",
    "    category_to_impact = {'Explicabilidad': 3, 'Equidad': 3, 'Robustez': 2, 'General': 1}\n",
    "    \n",
    "    risk_level = priority_to_risk.get(rec['priority'], 1)\n",
    "    impact_level = category_to_impact.get(rec['category'], 1)\n",
    "    risk_impact_data.append((risk_level, impact_level, rec['category']))\n",
    "\n",
    "if risk_impact_data:\n",
    "    x_vals = [item[0] for item in risk_impact_data]\n",
    "    y_vals = [item[1] for item in risk_impact_data]\n",
    "    colors_scatter = ['red' if x >= 3 else 'orange' if x >= 2 else 'green' for x in x_vals]\n",
    "    \n",
    "    axes[6].scatter(x_vals, y_vals, c=colors_scatter, alpha=0.7, s=100)\n",
    "    axes[6].set_xlabel('Nivel de Riesgo')\n",
    "    axes[6].set_ylabel('Nivel de Impacto')\n",
    "    axes[6].set_title('Matriz Riesgo vs Impacto')\n",
    "    axes[6].set_xlim([0.5, 3.5])\n",
    "    axes[6].set_ylim([0.5, 3.5])\n",
    "    axes[6].grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Tendencia de mejora sugerida\n",
    "months = ['Mes 1', 'Mes 3', 'Mes 6', 'Mes 12']\n",
    "current_score = rai_report['executive_summary']['overall_rai_score']\n",
    "projected_scores = [\n",
    "    current_score,\n",
    "    current_score + 10,  # Mejoras r√°pidas\n",
    "    current_score + 20,  # Mejoras sustanciales\n",
    "    min(95, current_score + 25)  # Mejoras a largo plazo\n",
    "]\n",
    "\n",
    "axes[7].plot(months, projected_scores, 'bo-', linewidth=3, markersize=8)\n",
    "axes[7].fill_between(months, projected_scores, alpha=0.3)\n",
    "axes[7].set_ylabel('Puntuaci√≥n RAI')\n",
    "axes[7].set_title('Proyecci√≥n de Mejora RAI')\n",
    "axes[7].set_ylim([0, 100])\n",
    "axes[7].grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Resumen de estado actual\n",
    "status_text = f\"\"\"\n",
    "ESTADO ACTUAL RAI\n",
    "\n",
    "Puntuaci√≥n General: {rai_report['executive_summary']['overall_rai_score']:.0f}/100\n",
    "Nivel: {rai_report['executive_summary']['rai_level']}\n",
    "\n",
    "Riesgo: {rai_report['risk_assessment']['overall_risk_level']}\n",
    "Recomendaciones: {len(rai_report['recommendations'])}\n",
    "\n",
    "Cumplimiento GDPR: {rai_report['compliance_score']['gdpr_compliance']:.0f}%\n",
    "Preparaci√≥n Regulatoria: {rai_report['compliance_score']['regulatory_readiness']:.0f}%\n",
    "\"\"\"\n",
    "\n",
    "axes[8].text(0.05, 0.95, status_text, transform=axes[8].transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "axes[8].set_xlim([0, 1])\n",
    "axes[8].set_ylim([0, 1])\n",
    "axes[8].axis('off')\n",
    "axes[8].set_title('Resumen Ejecutivo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rai_executive_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Dashboard ejecutivo RAI guardado como 'rai_executive_dashboard.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. REGISTRO EN AZURE ML Y GENERACI√ìN DE DOCUMENTACI√ìN FINAL\n",
    "print(\"\\nüîÑ REGISTRO RAI EN AZURE ML Y DOCUMENTACI√ìN\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Crear experimento para RAI\n",
    "RAI_EXPERIMENT = \"candidate-rai-analysis\"\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow.create_experiment(RAI_EXPERIMENT) if RAI_EXPERIMENT not in [exp.name for exp in mlflow.search_experiments()] else mlflow.get_experiment_by_name(RAI_EXPERIMENT).experiment_id):\n",
    "    \n",
    "    # Registrar m√©tricas RAI en MLflow\n",
    "    print(\"üìä Registrando m√©tricas RAI...\")\n",
    "    \n",
    "    # Puntuaciones principales\n",
    "    mlflow.log_metric(\"rai_overall_score\", rai_report['executive_summary']['overall_rai_score'])\n",
    "    mlflow.log_metric(\"explainability_score\", rai_report['executive_summary']['explainability_score'])\n",
    "    mlflow.log_metric(\"fairness_score\", rai_report['executive_summary']['fairness_score'])\n",
    "    mlflow.log_metric(\"robustness_score\", rai_report['executive_summary']['robustness_score'])\n",
    "    \n",
    "    # M√©tricas de cumplimiento\n",
    "    mlflow.log_metric(\"gdpr_compliance_score\", rai_report['compliance_score']['gdpr_compliance'])\n",
    "    mlflow.log_metric(\"ai_ethics_score\", rai_report['compliance_score']['ai_ethics_score'])\n",
    "    mlflow.log_metric(\"regulatory_readiness_score\", rai_report['compliance_score']['regulatory_readiness'])\n",
    "    \n",
    "    # M√©tricas de robustez detalladas\n",
    "    if 'bootstrap_stability' in robustness_analysis:\n",
    "        stability_stats = robustness_analysis['bootstrap_stability']\n",
    "        mlflow.log_metric(\"accuracy_cv\", stability_stats['accuracy_cv'])\n",
    "        mlflow.log_metric(\"f1_cv\", stability_stats['f1_cv'])\n",
    "        mlflow.log_metric(\"accuracy_stability_mean\", stability_stats['accuracy_mean'])\n",
    "        mlflow.log_metric(\"f1_stability_mean\", stability_stats['f1_mean'])\n",
    "    \n",
    "    # M√©tricas de equidad\n",
    "    if 'equity_metrics' in fairness_analysis and fairness_analysis['equity_metrics']:\n",
    "        equity_metrics = fairness_analysis['equity_metrics']\n",
    "        for metric_name, value in equity_metrics.items():\n",
    "            mlflow.log_metric(f\"fairness_{metric_name}\", value)\n",
    "    \n",
    "    # Registrar par√°metros\n",
    "    mlflow.log_param(\"evaluated_model\", training_info['best_model_name'])\n",
    "    mlflow.log_param(\"model_version\", registered_model.version)\n",
    "    mlflow.log_param(\"rai_analysis_date\", pd.Timestamp.now().strftime('%Y-%m-%d'))\n",
    "    mlflow.log_param(\"risk_level\", rai_report['risk_assessment']['overall_risk_level'])\n",
    "    mlflow.log_param(\"rai_level\", rai_report['executive_summary']['rai_level'])\n",
    "    mlflow.log_param(\"recommendations_count\", len(rai_report['recommendations']))\n",
    "    \n",
    "    # Registrar caracter√≠sticas m√°s importantes\n",
    "    if 'explainability' in rai_report['detailed_findings']:\n",
    "        top_features = rai_report['detailed_findings']['explainability']['top_3_features']\n",
    "        for i, feature in enumerate(top_features, 1):\n",
    "            mlflow.log_param(f\"top_explainable_feature_{i}\", feature)\n",
    "    \n",
    "    # Registrar artefactos (visualizaciones)\n",
    "    print(\"üñºÔ∏è Registrando visualizaciones RAI...\")\n",
    "    mlflow.log_artifact(\"explainability_analysis.png\")\n",
    "    mlflow.log_artifact(\"fairness_analysis.png\") \n",
    "    mlflow.log_artifact(\"robustness_analysis.png\")\n",
    "    mlflow.log_artifact(\"rai_executive_dashboard.png\")\n",
    "    \n",
    "    # Guardar reporte RAI completo como JSON\n",
    "    rai_report_clean = {}\n",
    "    for key, value in rai_report.items():\n",
    "        if isinstance(value, dict):\n",
    "            rai_report_clean[key] = {k: v for k, v in value.items() if not isinstance(v, pd.DataFrame)}\n",
    "        else:\n",
    "            rai_report_clean[key] = value\n",
    "    \n",
    "    with open('rai_complete_report.json', 'w') as f:\n",
    "        json.dump(rai_report_clean, f, indent=2, default=str)\n",
    "    \n",
    "    mlflow.log_artifact('rai_complete_report.json')\n",
    "    \n",
    "    current_run = mlflow.active_run()\n",
    "    rai_run_id = current_run.info.run_id\n",
    "    \n",
    "    print(f\"‚úÖ An√°lisis RAI registrado en MLflow\")\n",
    "    print(f\"üìã Run ID: {rai_run_id}\")\n",
    "\n",
    "# Generar reporte de texto detallado\n",
    "print(\"\\nüìÑ Generando documentaci√≥n RAI detallada...\")\n",
    "\n",
    "rai_documentation = f\"\"\"\n",
    "# REPORTE DE INTELIGENCIA ARTIFICIAL RESPONSABLE (RAI)\n",
    "## Modelo de Selecci√≥n de Candidatos\n",
    "\n",
    "**Fecha de an√°lisis:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Modelo evaluado:** {training_info['best_model_name']} v{registered_model.version}\n",
    "**Run ID de an√°lisis:** {rai_run_id}\n",
    "\n",
    "---\n",
    "\n",
    "## RESUMEN EJECUTIVO\n",
    "\n",
    "### Puntuaciones Generales\n",
    "- **Puntuaci√≥n RAI General:** {rai_report['executive_summary']['overall_rai_score']:.0f}/100 ({rai_report['executive_summary']['rai_level']})\n",
    "- **Explicabilidad:** {rai_report['executive_summary']['explainability_score']:.0f}/100\n",
    "- **Equidad:** {rai_report['executive_summary']['fairness_score']:.0f}/100\n",
    "- **Robustez:** {rai_report['executive_summary']['robustness_score']:.0f}/100\n",
    "\n",
    "### Evaluaci√≥n de Riesgo\n",
    "- **Nivel de riesgo:** {rai_report['risk_assessment']['overall_risk_level']}\n",
    "- **Prioridad de mitigaci√≥n:** {rai_report['risk_assessment']['mitigation_priority']}\n",
    "\n",
    "### Cumplimiento Regulatorio\n",
    "- **Cumplimiento GDPR:** {rai_report['compliance_score']['gdpr_compliance']:.0f}%\n",
    "- **Preparaci√≥n regulatoria:** {rai_report['compliance_score']['regulatory_readiness']:.0f}%\n",
    "\n",
    "---\n",
    "\n",
    "## AN√ÅLISIS DETALLADO\n",
    "\n",
    "### 1. EXPLICABILIDAD DEL MODELO\n",
    "\"\"\"\n",
    "\n",
    "if 'explainability' in rai_report['detailed_findings']:\n",
    "    explainability_findings = rai_report['detailed_findings']['explainability']\n",
    "    rai_documentation += f\"\"\"\n",
    "**Caracter√≠sticas m√°s importantes:**\n",
    "\"\"\"\n",
    "    for i, feature in enumerate(explainability_findings['top_3_features'], 1):\n",
    "        rai_documentation += f\"{i}. {feature}\\n\"\n",
    "    \n",
    "    rai_documentation += f\"\"\"\n",
    "**Concentraci√≥n de importancia:** {explainability_findings['importance_concentration']:.2f}\n",
    "**Caracter√≠sticas para 80% de explicaci√≥n:** {explainability_findings['features_for_80_percent']}\n",
    "\n",
    "**Interpretaci√≥n:** \"\"\"\n",
    "    if explainability_findings['importance_concentration'] > 0.8:\n",
    "        rai_documentation += \"El modelo es altamente explicable con pocas caracter√≠sticas dominantes.\"\n",
    "    elif explainability_findings['importance_concentration'] > 0.6:\n",
    "        rai_documentation += \"El modelo tiene explicabilidad moderada con caracter√≠sticas importantes bien definidas.\"\n",
    "    else:\n",
    "        rai_documentation += \"El modelo distribuye importancia entre muchas caracter√≠sticas, requiere t√©cnicas adicionales de explicabilidad.\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "### 2. AN√ÅLISIS DE EQUIDAD\n",
    "\"\"\"\n",
    "\n",
    "if 'fairness' in rai_report['detailed_findings']:\n",
    "    fairness_findings = rai_report['detailed_findings']['fairness']\n",
    "    rai_documentation += f\"\"\"\n",
    "**Grupos analizados:** {fairness_findings['number_of_groups_analyzed']}\n",
    "**Disparidad m√°xima entre grupos:** {fairness_findings['max_group_disparity']:.3f}\n",
    "**Grupos con alta disparidad:** {fairness_findings['groups_with_high_disparity']}\n",
    "\n",
    "**Interpretaci√≥n:** \"\"\"\n",
    "    if fairness_findings['max_group_disparity'] < 0.05:\n",
    "        rai_documentation += \"El modelo muestra alta equidad entre grupos analizados.\"\n",
    "    elif fairness_findings['max_group_disparity'] < 0.1:\n",
    "        rai_documentation += \"El modelo muestra equidad aceptable con disparidades menores.\"\n",
    "    else:\n",
    "        rai_documentation += \"Se detectaron disparidades significativas que requieren atenci√≥n.\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "### 3. AN√ÅLISIS DE ROBUSTEZ\n",
    "\"\"\"\n",
    "\n",
    "if 'robustness' in rai_report['detailed_findings']:\n",
    "    robustness_findings = rai_report['detailed_findings']['robustness']\n",
    "    rai_documentation += f\"\"\"\n",
    "**Coeficiente de variaci√≥n - Accuracy:** {robustness_findings['accuracy_stability_cv']:.4f}\n",
    "**Coeficiente de variaci√≥n - F1:** {robustness_findings['f1_stability_cv']:.4f}\n",
    "**Nivel de estabilidad:** {robustness_findings['model_stability_level']}\n",
    "\n",
    "**Interpretaci√≥n:** \"\"\"\n",
    "    if robustness_findings['model_stability_level'] == 'ALTA':\n",
    "        rai_documentation += \"El modelo muestra alta estabilidad y robustez.\"\n",
    "    elif robustness_findings['model_stability_level'] == 'MEDIA':\n",
    "        rai_documentation += \"El modelo tiene estabilidad moderada, aceptable para producci√≥n.\"\n",
    "    else:\n",
    "        rai_documentation += \"El modelo muestra baja estabilidad y requiere mejoras antes de producci√≥n.\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## RECOMENDACIONES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i, rec in enumerate(rai_report['recommendations'], 1):\n",
    "    rai_documentation += f\"\"\"\n",
    "### {i}. {rec['category']} (Prioridad: {rec['priority']})\n",
    "**Recomendaci√≥n:** {rec['recommendation']}\n",
    "\n",
    "**Acciones espec√≠ficas:**\n",
    "\"\"\"\n",
    "    for action in rec['action_items']:\n",
    "        rai_documentation += f\"- {action}\\n\"\n",
    "    rai_documentation += \"\\n\"\n",
    "\n",
    "if rai_report['risk_assessment']['risk_factors']:\n",
    "    rai_documentation += f\"\"\"\n",
    "---\n",
    "\n",
    "## FACTORES DE RIESGO IDENTIFICADOS\n",
    "\n",
    "\"\"\"\n",
    "    for i, risk_factor in enumerate(rai_report['risk_assessment']['risk_factors'], 1):\n",
    "        rai_documentation += f\"{i}. {risk_factor}\\n\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## CONCLUSIONES Y PR√ìXIMOS PASOS\n",
    "\n",
    "### Estado Actual\n",
    "El modelo presenta un nivel RAI **{rai_report['executive_summary']['rai_level']}** con una puntuaci√≥n de {rai_report['executive_summary']['overall_rai_score']:.0f}/100. El riesgo general se clasifica como **{rai_report['risk_assessment']['overall_risk_level']}**.\n",
    "\n",
    "### Recomendaciones Prioritarias\n",
    "\"\"\"\n",
    "\n",
    "high_priority_recs = [r for r in rai_report['recommendations'] if r['priority'] == 'ALTA']\n",
    "if high_priority_recs:\n",
    "    rai_documentation += f\"Se requiere atenci√≥n inmediata en {len(high_priority_recs)} √°rea(s) cr√≠tica(s):\\n\"\n",
    "    for rec in high_priority_recs:\n",
    "        rai_documentation += f\"- {rec['category']}: {rec['recommendation']}\\n\"\n",
    "else:\n",
    "    rai_documentation += \"No se identificaron √°reas que requieran atenci√≥n inmediata.\\n\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "### Siguientes Pasos\n",
    "1. **Inmediato (0-1 mes):** Implementar recomendaciones de alta prioridad\n",
    "2. **Corto plazo (1-3 meses):** Abordar recomendaciones de prioridad media\n",
    "3. **Largo plazo (3+ meses):** Implementar mejoras adicionales y monitoreo continuo\n",
    "\n",
    "### Monitoreo Continuo\n",
    "- Revisar m√©tricas RAI cada 3 meses\n",
    "- Monitorear equidad en producci√≥n\n",
    "- Actualizar documentaci√≥n de explicabilidad\n",
    "- Evaluar nuevos riesgos emergentes\n",
    "\n",
    "---\n",
    "\n",
    "**Documento generado autom√°ticamente por el sistema RAI**\n",
    "**√öltima actualizaci√≥n:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# Guardar documentaci√≥n\n",
    "with open('rai_detailed_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(rai_documentation)\n",
    "\n",
    "# Registro en MLflow\n",
    "with mlflow.start_run(run_id=rai_run_id):\n",
    "    mlflow.log_artifact('rai_detailed_report.md')\n",
    "\n",
    "print(f\"‚úÖ Documentaci√≥n RAI completa generada\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(f\"\\nüéØ RESUMEN FINAL DEL AN√ÅLISIS RAI\")\n",
    "print(\"=\"*55)\n",
    "print(f\"üìä Puntuaci√≥n RAI General: {rai_report['executive_summary']['overall_rai_score']:.0f}/100\")\n",
    "print(f\"üèÜ Nivel RAI: {rai_report['executive_summary']['rai_level']}\")\n",
    "print(f\"‚ö†Ô∏è  Nivel de riesgo: {rai_report['risk_assessment']['overall_risk_level']}\")\n",
    "print(f\"üìã Recomendaciones generadas: {len(rai_report['recommendations'])}\")\n",
    "print(f\"üîÑ Run ID RAI: {rai_run_id}\")\n",
    "\n",
    "print(f\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "print(f\"  - explainability_analysis.png\")\n",
    "print(f\"  - fairness_analysis.png\") \n",
    "print(f\"  - robustness_analysis.png\")\n",
    "print(f\"  - rai_executive_dashboard.png\")\n",
    "print(f\"  - rai_complete_report.json\")\n",
    "print(f\"  - rai_detailed_report.md\")\n",
    "\n",
    "print(f\"\\n‚úÖ AN√ÅLISIS RAI COMPLETADO\")\n",
    "print(f\"üîó Todos los artefactos disponibles en Azure ML Studio\")\n",
    "print(f\"üìã Experimento: {RAI_EXPERIMENT}\")\n",
    "\n",
    "# Guardar m√©tricas finales para reporte\n",
    "final_rai_metrics = {\n",
    "    'overall_score': rai_report['executive_summary']['overall_rai_score'],\n",
    "    'risk_level': rai_report['risk_assessment']['overall_risk_level'],\n",
    "    'recommendations_count': len(rai_report['recommendations']),\n",
    "    'high_priority_recommendations': len([r for r in rai_report['recommendations'] if r['priority'] == 'ALTA']),\n",
    "    'compliance_ready': rai_report['compliance_score']['regulatory_readiness'] >= 70\n",
    "}\n",
    "\n",
    "print(f\"\\nüìà M√âTRICAS FINALES PARA SEGUIMIENTO:\")\n",
    "for metric, value in final_rai_metrics.items():\n",
    "    print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(f\"\\nüéâ Pipeline RAI completo exitosamente!\")\n",
    "print(f\"üîÑ Ready para revisi√≥n ejecutiva y implementaci√≥n en producci√≥n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
