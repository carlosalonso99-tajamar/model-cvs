{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DASHBOARD DE INTELIGENCIA ARTIFICIAL RESPONSABLE (RAI)\n",
    "# ================================================================\n",
    "\n",
    "# 1. CONFIGURACIÓN Y IMPORTS PARA RAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import shap\n",
    "from typing import Dict, List, Any, Tuple\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Azure ML imports\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run, Model\n",
    "from azureml.core.model import Model as AMLModel\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# RAI y análisis de equidad\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Análisis estadístico\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ks_2samp\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"🛡️  DASHBOARD DE INTELIGENCIA ARTIFICIAL RESPONSABLE\")\n",
    "print(\"=\"*70)\n",
    "print(\"📋 Análisis de: Equidad, Explicabilidad, Robustez y Transparencia\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Conectar al workspace\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(f\"✅ Conectado al workspace: {ws.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error conectando al workspace: {e}\")\n",
    "    raise\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "\n",
    "print(f\"🔄 Cargando modelo y datos para análisis RAI...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CARGA DE MODELO Y DATOS PARA ANÁLISIS RAI\n",
    "print(\"\\n📥 CARGA DE MODELO Y DATOS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Cargar el modelo registrado más reciente\n",
    "MODEL_NAME = \"candidate-selection-model\"\n",
    "\n",
    "try:\n",
    "    # Obtener la versión más reciente del modelo\n",
    "    registered_model = AMLModel(ws, name=MODEL_NAME)\n",
    "    print(f\"✅ Modelo encontrado: {MODEL_NAME}\")\n",
    "    print(f\"📋 Versión: {registered_model.version}\")\n",
    "    \n",
    "    # Descargar artefactos del modelo\n",
    "    model_path = registered_model.download(target_dir=\"./model_artifacts\")\n",
    "    print(f\"📁 Artefactos descargados en: {model_path}\")\n",
    "    \n",
    "    # Cargar modelo y scaler\n",
    "    model = joblib.load(f\"{model_path}/model.pkl\")\n",
    "    scaler = joblib.load(f\"{model_path}/scaler.pkl\")\n",
    "    \n",
    "    # Cargar metadatos\n",
    "    with open(f\"{model_path}/feature_names.json\", 'r') as f:\n",
    "        feature_metadata = json.load(f)\n",
    "    \n",
    "    with open(f\"{model_path}/notebook_info.json\", 'r') as f:\n",
    "        training_info = json.load(f)\n",
    "    \n",
    "    print(f\"✅ Modelo cargado: {type(model).__name__}\")\n",
    "    print(f\"📊 Features: {feature_metadata['feature_count']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error cargando modelo registrado: {e}\")\n",
    "    print(\"💡 Asegúrate de haber ejecutado el notebook de entrenamiento primero\")\n",
    "    raise\n",
    "\n",
    "# Cargar datasets\n",
    "try:\n",
    "    # Cargar datos de test y validación\n",
    "    test_data = pd.read_parquet(f\"{model_path}/test_data.parquet\")\n",
    "    val_data = pd.read_parquet(f\"{model_path}/val_data.parquet\")\n",
    "    \n",
    "    print(f\"\\n📊 Datos cargados:\")\n",
    "    print(f\"  Test: {test_data.shape}\")\n",
    "    print(f\"  Validación: {val_data.shape}\")\n",
    "    \n",
    "    # Separar features y targets\n",
    "    feature_names = feature_metadata['feature_names']\n",
    "    \n",
    "    X_test = test_data[feature_names]\n",
    "    y_test_true = test_data['y_true']\n",
    "    y_test_pred = test_data['y_pred']\n",
    "    y_test_proba = test_data['y_proba']\n",
    "    \n",
    "    # Combinar datos para análisis más completo\n",
    "    X_combined = pd.concat([X_test, val_data[feature_names]], ignore_index=True)\n",
    "    y_combined_true = pd.concat([y_test_true, val_data['y_true']], ignore_index=True)\n",
    "    y_combined_pred = pd.concat([y_test_pred, val_data['y_pred']], ignore_index=True)\n",
    "    y_combined_proba = pd.concat([y_test_proba, val_data['y_proba']], ignore_index=True)\n",
    "    \n",
    "    print(f\"  Datos combinados: {X_combined.shape}\")\n",
    "    print(f\"✅ Datos organizados para análisis RAI\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error cargando datos: {e}\")\n",
    "    raise\n",
    "\n",
    "# Cargar datos originales procesados para análisis de equidad\n",
    "try:\n",
    "    # Intentar cargar datos procesados con información demográfica\n",
    "    processed_data_path = \"data/processed/processed_candidates.parquet\"\n",
    "    if Path(processed_data_path).exists():\n",
    "        full_processed_data = pd.read_parquet(processed_data_path)\n",
    "        print(f\"📊 Datos originales cargados: {full_processed_data.shape}\")\n",
    "        \n",
    "        # Verificar columnas disponibles para análisis de equidad\n",
    "        demographic_cols = []\n",
    "        if 'gender' in full_processed_data.columns:\n",
    "            demographic_cols.append('gender')\n",
    "        if 'age_range' in full_processed_data.columns:\n",
    "            demographic_cols.append('age_range')\n",
    "        if 'location' in full_processed_data.columns:\n",
    "            demographic_cols.append('location')\n",
    "        if 'education_level' in full_processed_data.columns:\n",
    "            demographic_cols.append('education_level')\n",
    "            \n",
    "        print(f\"📋 Columnas demográficas disponibles: {demographic_cols}\")\n",
    "        demographic_data_available = len(demographic_cols) > 0\n",
    "    else:\n",
    "        print(\"⚠️  Datos originales no encontrados - análisis de equidad limitado\")\n",
    "        demographic_data_available = False\n",
    "        full_processed_data = None\n",
    "        demographic_cols = []\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Error cargando datos demográficos: {e}\")\n",
    "    demographic_data_available = False\n",
    "    full_processed_data = None\n",
    "    demographic_cols = []\n",
    "\n",
    "print(f\"\\n📋 CONFIGURACIÓN PARA ANÁLISIS RAI:\")\n",
    "print(f\"  Modelo: {training_info['best_model_name']}\")\n",
    "print(f\"  Muestras para análisis: {len(X_combined):,}\")\n",
    "print(f\"  Features: {len(feature_names)}\")\n",
    "print(f\"  Análisis demográfico: {'✅ Disponible' if demographic_data_available else '❌ No disponible'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ANÁLISIS DE EXPLICABILIDAD CON SHAP\n",
    "print(\"\\n🔍 ANÁLISIS DE EXPLICABILIDAD DEL MODELO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def analyze_model_explainability(model, X_sample, feature_names, max_samples=500):\n",
    "    \"\"\"Realiza análisis completo de explicabilidad usando SHAP\"\"\"\n",
    "    \n",
    "    explainability_results = {}\n",
    "    \n",
    "    # Tomar muestra para SHAP (computacionalmente costoso)\n",
    "    if len(X_sample) > max_samples:\n",
    "        sample_idx = np.random.choice(len(X_sample), max_samples, replace=False)\n",
    "        X_shap = X_sample.iloc[sample_idx]\n",
    "        print(f\"📊 Usando muestra de {max_samples} observaciones para SHAP\")\n",
    "    else:\n",
    "        X_shap = X_sample\n",
    "        print(f\"📊 Usando todas las {len(X_sample)} observaciones para SHAP\")\n",
    "    \n",
    "    try:\n",
    "        print(\"🔄 Calculando valores SHAP...\")\n",
    "        \n",
    "        # Crear explainer según tipo de modelo\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            # Para modelos probabilísticos\n",
    "            if hasattr(model, 'tree_'):\n",
    "                # Modelos basados en árboles\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "            else:\n",
    "                # Otros modelos - usar KernelExplainer\n",
    "                explainer = shap.KernelExplainer(\n",
    "                    model.predict_proba, \n",
    "                    X_shap.sample(min(100, len(X_shap)))\n",
    "                )\n",
    "        else:\n",
    "            # Modelos de regresión\n",
    "            explainer = shap.KernelExplainer(\n",
    "                model.predict, \n",
    "                X_shap.sample(min(100, len(X_shap)))\n",
    "            )\n",
    "        \n",
    "        # Calcular valores SHAP\n",
    "        shap_values = explainer.shap_values(X_shap)\n",
    "        \n",
    "        # Para modelos de clasificación binaria, tomar valores para clase positiva\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_values_positive = shap_values[1]\n",
    "        else:\n",
    "            shap_values_positive = shap_values\n",
    "        \n",
    "        explainability_results['shap_values'] = shap_values_positive\n",
    "        explainability_results['shap_data'] = X_shap\n",
    "        explainability_results['explainer'] = explainer\n",
    "        \n",
    "        # Calcular importancia global\n",
    "        feature_importance_shap = np.abs(shap_values_positive).mean(axis=0)\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': feature_importance_shap\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        explainability_results['global_importance'] = importance_df\n",
    "        \n",
    "        print(\"✅ Análisis SHAP completado\")\n",
    "        \n",
    "        return explainability_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error en análisis SHAP: {e}\")\n",
    "        print(\"📝 Realizando análisis de explicabilidad alternativo...\")\n",
    "        \n",
    "        # Análisis alternativo usando permutation importance\n",
    "        try:\n",
    "            perm_importance = permutation_importance(\n",
    "                model, X_shap, \n",
    "                model.predict(X_shap) if not hasattr(model, 'predict_proba') else np.argmax(model.predict_proba(X_shap), axis=1),\n",
    "                n_repeats=5, random_state=42\n",
    "            )\n",
    "            \n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': feature_names,\n",
    "                'importance': perm_importance.importances_mean\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            explainability_results['global_importance'] = importance_df\n",
    "            explainability_results['shap_available'] = False\n",
    "            \n",
    "            print(\"✅ Análisis de explicabilidad alternativo completado\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Error en análisis alternativo: {e2}\")\n",
    "            explainability_results['error'] = str(e2)\n",
    "        \n",
    "        return explainability_results\n",
    "\n",
    "# Realizar análisis de explicabilidad\n",
    "explainability_analysis = analyze_model_explainability(\n",
    "    model, X_combined, feature_names, max_samples=300\n",
    ")\n",
    "\n",
    "# Visualizar resultados de explicabilidad\n",
    "if 'global_importance' in explainability_analysis:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Importancia global de características\n",
    "    top_features = explainability_analysis['global_importance'].head(15)\n",
    "    \n",
    "    axes[0,0].barh(range(len(top_features)), top_features['importance'])\n",
    "    axes[0,0].set_yticks(range(len(top_features)))\n",
    "    axes[0,0].set_yticklabels(top_features['feature'])\n",
    "    axes[0,0].set_xlabel('Importancia Global')\n",
    "    axes[0,0].set_title('Top 15 Características más Importantes\\n(Análisis de Explicabilidad)')\n",
    "    axes[0,0].invert_yaxis()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Distribución de importancias\n",
    "    axes[0,1].hist(explainability_analysis['global_importance']['importance'], \n",
    "                   bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[0,1].set_xlabel('Importancia')\n",
    "    axes[0,1].set_ylabel('Frecuencia')\n",
    "    axes[0,1].set_title('Distribución de Importancias')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Importancia acumulada\n",
    "    sorted_importance = explainability_analysis['global_importance'].sort_values('importance', ascending=False)\n",
    "    cumulative_importance = np.cumsum(sorted_importance['importance']) / sorted_importance['importance'].sum()\n",
    "    \n",
    "    axes[1,0].plot(range(1, len(cumulative_importance) + 1), cumulative_importance, 'b-', linewidth=2)\n",
    "    axes[1,0].axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80% importancia')\n",
    "    axes[1,0].axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='90% importancia')\n",
    "    axes[1,0].set_xlabel('Número de Características')\n",
    "    axes[1,0].set_ylabel('Importancia Acumulada')\n",
    "    axes[1,0].set_title('Importancia Acumulada de Características')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Top vs Bottom features\n",
    "    top_5 = explainability_analysis['global_importance'].head(5)\n",
    "    bottom_5 = explainability_analysis['global_importance'].tail(5)\n",
    "    \n",
    "    # Crear comparación\n",
    "    comparison_features = list(top_5['feature']) + list(bottom_5['feature'])\n",
    "    comparison_values = list(top_5['importance']) + list(bottom_5['importance'])\n",
    "    colors = ['darkgreen'] * 5 + ['darkred'] * 5\n",
    "    \n",
    "    axes[1,1].barh(range(len(comparison_features)), comparison_values, color=colors, alpha=0.7)\n",
    "    axes[1,1].set_yticks(range(len(comparison_features)))\n",
    "    axes[1,1].set_yticklabels(comparison_features)\n",
    "    axes[1,1].set_xlabel('Importancia')\n",
    "    axes[1,1].set_title('Top 5 vs Bottom 5 Características')\n",
    "    axes[1,1].invert_yaxis()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('explainability_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"✅ Análisis de explicabilidad guardado como 'explainability_analysis.png'\")\n",
    "    \n",
    "    # Mostrar estadísticas de explicabilidad\n",
    "    print(f\"\\n📊 ESTADÍSTICAS DE EXPLICABILIDAD:\")\n",
    "    print(f\"  Top 5 características explican: {cumulative_importance.iloc[4]:.1%} de la importancia\")\n",
    "    print(f\"  Top 10 características explican: {cumulative_importance.iloc[9]:.1%} de la importancia\")\n",
    "    print(f\"  Características para 80% importancia: {(cumulative_importance >= 0.8).idxmax() + 1}\")\n",
    "    print(f\"  Características para 90% importancia: {(cumulative_importance >= 0.9).idxmax() + 1}\")\n",
    "    \n",
    "    # Guardar top features para análisis posterior\n",
    "    top_important_features = explainability_analysis['global_importance'].head(10)['feature'].tolist()\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No se pudo completar el análisis de explicabilidad\")\n",
    "    top_important_features = feature_names[:10]  # Fallback\n",
    "\n",
    "print(f\"\\n📋 TOP 10 CARACTERÍSTICAS MÁS EXPLICATIVAS:\")\n",
    "for i, feature in enumerate(top_important_features, 1):\n",
    "    importance_val = explainability_analysis['global_importance'][\n",
    "        explainability_analysis['global_importance']['feature'] == feature\n",
    "    ]['importance'].iloc[0]\n",
    "    print(f\"  {i:2d}. {feature:30s} (importancia: {importance_val:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ANÁLISIS DE EQUIDAD Y SESGO\n",
    "print(\"\\n⚖️ ANÁLISIS DE EQUIDAD Y SESGO DEL MODELO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "def analyze_fairness_and_bias(X_data, y_true, y_pred, y_proba, feature_names):\n",
    "    \"\"\"Analiza equidad y sesgo en las predicciones del modelo\"\"\"\n",
    "    \n",
    "    fairness_results = {}\n",
    "    \n",
    "    # 1. Análisis de disparidad en características técnicas vs no técnicas\n",
    "    print(\"📊 Análisis de disparidad por tipo de características...\")\n",
    "    \n",
    "    # Identificar características técnicas vs demográficas/blandas\n",
    "    technical_features = []\n",
    "    soft_features = []\n",
    "    \n",
    "    for feature in feature_names:\n",
    "        feature_lower = feature.lower()\n",
    "        if any(tech_word in feature_lower for tech_word in \n",
    "               ['skill', 'experience', 'years', 'certification', 'degree', 'technical', 'programming', 'software']):\n",
    "            technical_features.append(feature)\n",
    "        else:\n",
    "            soft_features.append(feature)\n",
    "    \n",
    "    print(f\"  Características técnicas: {len(technical_features)}\")\n",
    "    print(f\"  Características no técnicas: {len(soft_features)}\")\n",
    "    \n",
    "    # 2. Análisis de correlación entre características y predicciones\n",
    "    correlation_analysis = {}\n",
    "    \n",
    "    # Calcular correlaciones significativas\n",
    "    for feature in feature_names:\n",
    "        if feature in X_data.columns:\n",
    "            # Correlación con predicción\n",
    "            corr_pred = np.corrcoef(X_data[feature], y_pred)[0,1]\n",
    "            # Correlación con probabilidad\n",
    "            corr_proba = np.corrcoef(X_data[feature], y_proba)[0,1]\n",
    "            # Correlación con truth\n",
    "            corr_truth = np.corrcoef(X_data[feature], y_true)[0,1]\n",
    "            \n",
    "            correlation_analysis[feature] = {\n",
    "                'corr_prediction': corr_pred if not np.isnan(corr_pred) else 0,\n",
    "                'corr_probability': corr_proba if not np.isnan(corr_proba) else 0,\n",
    "                'corr_truth': corr_truth if not np.isnan(corr_truth) else 0\n",
    "            }\n",
    "    \n",
    "    fairness_results['correlation_analysis'] = correlation_analysis\n",
    "    \n",
    "    # 3. Análisis de distribución de probabilidades por cuartiles de características importantes\n",
    "    print(\"📈 Análisis de distribución por cuartiles...\")\n",
    "    \n",
    "    quartile_analysis = {}\n",
    "    for feature in top_important_features[:5]:  # Top 5 características\n",
    "        if feature in X_data.columns:\n",
    "            # Dividir en cuartiles\n",
    "            quartiles = pd.qcut(X_data[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "            \n",
    "            quartile_stats = {}\n",
    "            for q in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "                mask = (quartiles == q)\n",
    "                if mask.sum() > 0:\n",
    "                    quartile_stats[q] = {\n",
    "                        'count': mask.sum(),\n",
    "                        'positive_rate': y_true[mask].mean(),\n",
    "                        'predicted_positive_rate': y_pred[mask].mean(),\n",
    "                        'mean_probability': y_proba[mask].mean(),\n",
    "                        'std_probability': y_proba[mask].std()\n",
    "                    }\n",
    "            \n",
    "            quartile_analysis[feature] = quartile_stats\n",
    "    \n",
    "    fairness_results['quartile_analysis'] = quartile_analysis\n",
    "    \n",
    "    # 4. Análisis de paridad demográfica simulada\n",
    "    print(\"🎯 Análisis de paridad demográfica...\")\n",
    "    \n",
    "    # Crear grupos sintéticos basados en características del modelo\n",
    "    # Grupo 1: Alta experiencia + alta educación\n",
    "    # Grupo 2: Experiencia media\n",
    "    # Grupo 3: Baja experiencia\n",
    "    \n",
    "    demographic_parity = {}\n",
    "    \n",
    "    # Identificar features relacionadas con experiencia y educación\n",
    "    experience_features = [f for f in feature_names if 'experience' in f.lower() or 'years' in f.lower()]\n",
    "    education_features = [f for f in feature_names if 'education' in f.lower() or 'degree' in f.lower()]\n",
    "    \n",
    "    if experience_features and education_features:\n",
    "        # Crear score compuesto\n",
    "        exp_score = X_data[experience_features].mean(axis=1) if len(experience_features) > 1 else X_data[experience_features[0]]\n",
    "        edu_score = X_data[education_features].mean(axis=1) if len(education_features) > 1 else X_data[education_features[0]]\n",
    "        \n",
    "        # Crear grupos basados en terciles\n",
    "        exp_terciles = pd.qcut(exp_score, q=3, labels=['Low_Exp', 'Mid_Exp', 'High_Exp'], duplicates='drop')\n",
    "        edu_terciles = pd.qcut(edu_score, q=3, labels=['Low_Edu', 'Mid_Edu', 'High_Edu'], duplicates='drop')\n",
    "        \n",
    "        # Analizar paridad entre grupos\n",
    "        for exp_group in ['Low_Exp', 'Mid_Exp', 'High_Exp']:\n",
    "            for edu_group in ['Low_Edu', 'Mid_Edu', 'High_Edu']:\n",
    "                group_mask = (exp_terciles == exp_group) & (edu_terciles == edu_group)\n",
    "                if group_mask.sum() > 10:  # Solo grupos con suficientes muestras\n",
    "                    group_name = f\"{exp_group}_{edu_group}\"\n",
    "                    demographic_parity[group_name] = {\n",
    "                        'count': group_mask.sum(),\n",
    "                        'positive_rate': y_true[group_mask].mean(),\n",
    "                        'predicted_positive_rate': y_pred[group_mask].mean(),\n",
    "                        'mean_probability': y_proba[group_mask].mean(),\n",
    "                        'false_positive_rate': ((y_pred[group_mask] == 1) & (y_true[group_mask] == 0)).sum() / max(1, (y_true[group_mask] == 0).sum()),\n",
    "                        'false_negative_rate': ((y_pred[group_mask] == 0) & (y_true[group_mask] == 1)).sum() / max(1, (y_true[group_mask] == 1).sum())\n",
    "                    }\n",
    "    \n",
    "    fairness_results['demographic_parity'] = demographic_parity\n",
    "    \n",
    "    # 5. Métricas de equidad\n",
    "    equity_metrics = {}\n",
    "    \n",
    "    # Calcular métricas de equidad entre grupos\n",
    "    if demographic_parity:\n",
    "        positive_rates = [group['predicted_positive_rate'] for group in demographic_parity.values()]\n",
    "        fpr_rates = [group['false_positive_rate'] for group in demographic_parity.values()]\n",
    "        fnr_rates = [group['false_negative_rate'] for group in demographic_parity.values()]\n",
    "        \n",
    "        equity_metrics = {\n",
    "            'demographic_parity_difference': max(positive_rates) - min(positive_rates),\n",
    "            'equalized_odds_difference_fpr': max(fpr_rates) - min(fpr_rates),\n",
    "            'equalized_odds_difference_fnr': max(fnr_rates) - min(fnr_rates),\n",
    "            'statistical_parity_ratio': min(positive_rates) / max(positive_rates) if max(positive_rates) > 0 else 0\n",
    "        }\n",
    "    \n",
    "    fairness_results['equity_metrics'] = equity_metrics\n",
    "    fairness_results['technical_features'] = technical_features\n",
    "    fairness_results['soft_features'] = soft_features\n",
    "    \n",
    "    return fairness_results\n",
    "\n",
    "# Realizar análisis de equidad\n",
    "fairness_analysis = analyze_fairness_and_bias(\n",
    "    X_combined, y_combined_true, y_combined_pred, y_combined_proba, feature_names\n",
    ")\n",
    "\n",
    "# Visualizar análisis de equidad\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# 1. Correlaciones features-predicción\n",
    "if 'correlation_analysis' in fairness_analysis:\n",
    "    corr_data = fairness_analysis['correlation_analysis']\n",
    "    features = list(corr_data.keys())[:15]  # Top 15\n",
    "    pred_corrs = [corr_data[f]['corr_prediction'] for f in features]\n",
    "    \n",
    "    axes[plot_idx].barh(range(len(features)), pred_corrs)\n",
    "    axes[plot_idx].set_yticks(range(len(features)))\n",
    "    axes[plot_idx].set_yticklabels(features)\n",
    "    axes[plot_idx].set_xlabel('Correlación con Predicción')\n",
    "    axes[plot_idx].set_title('Correlación Features-Predicción')\n",
    "    axes[plot_idx].invert_yaxis()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 2. Distribución por cuartiles de feature más importante\n",
    "if 'quartile_analysis' in fairness_analysis and fairness_analysis['quartile_analysis']:\n",
    "    top_feature = list(fairness_analysis['quartile_analysis'].keys())[0]\n",
    "    quartile_data = fairness_analysis['quartile_analysis'][top_feature]\n",
    "    \n",
    "    quartiles = list(quartile_data.keys())\n",
    "    true_rates = [quartile_data[q]['positive_rate'] for q in quartiles]\n",
    "    pred_rates = [quartile_data[q]['predicted_positive_rate'] for q in quartiles]\n",
    "    \n",
    "    x = np.arange(len(quartiles))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[plot_idx].bar(x - width/2, true_rates, width, label='Tasa Real', alpha=0.8)\n",
    "    axes[plot_idx].bar(x + width/2, pred_rates, width, label='Tasa Predicha', alpha=0.8)\n",
    "    axes[plot_idx].set_xlabel('Cuartil')\n",
    "    axes[plot_idx].set_ylabel('Tasa Positiva')\n",
    "    axes[plot_idx].set_title(f'Tasas por Cuartil - {top_feature}')\n",
    "    axes[plot_idx].set_xticks(x)\n",
    "    axes[plot_idx].set_xticklabels(quartiles)\n",
    "    axes[plot_idx].legend()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 3. Paridad demográfica\n",
    "if 'demographic_parity' in fairness_analysis and fairness_analysis['demographic_parity']:\n",
    "    parity_data = fairness_analysis['demographic_parity']\n",
    "    groups = list(parity_data.keys())\n",
    "    positive_rates = [parity_data[g]['predicted_positive_rate'] for g in groups]\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(groups)))\n",
    "    axes[plot_idx].bar(range(len(groups)), positive_rates, color=colors, alpha=0.8)\n",
    "    axes[plot_idx].set_xlabel('Grupo Demográfico')\n",
    "    axes[plot_idx].set_ylabel('Tasa Positiva Predicha')\n",
    "    axes[plot_idx].set_title('Paridad Demográfica por Grupos')\n",
    "    axes[plot_idx].set_xticks(range(len(groups)))\n",
    "    axes[plot_idx].set_xticklabels(groups, rotation=45, ha='right')\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 4. Métricas de equidad\n",
    "if 'equity_metrics' in fairness_analysis and fairness_analysis['equity_metrics']:\n",
    "    equity_data = fairness_analysis['equity_metrics']\n",
    "    metrics = list(equity_data.keys())\n",
    "    values = list(equity_data.values())\n",
    "    \n",
    "    colors = ['red' if abs(v) > 0.1 else 'green' for v in values]\n",
    "    axes[plot_idx].bar(range(len(metrics)), values, color=colors, alpha=0.7)\n",
    "    axes[plot_idx].set_xlabel('Métrica de Equidad')\n",
    "    axes[plot_idx].set_ylabel('Valor')\n",
    "    axes[plot_idx].set_title('Métricas de Equidad\\n(Verde: Bueno, Rojo: Problemático)')\n",
    "    axes[plot_idx].set_xticks(range(len(metrics)))\n",
    "    axes[plot_idx].set_xticklabels([m.replace('_', '\\n') for m in metrics], rotation=45, ha='right')\n",
    "    axes[plot_idx].axhline(y=0.1, color='orange', linestyle='--', alpha=0.7, label='Umbral preocupante')\n",
    "    axes[plot_idx].axhline(y=-0.1, color='orange', linestyle='--', alpha=0.7)\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 5. Distribución de características técnicas vs no técnicas\n",
    "tech_features = fairness_analysis.get('technical_features', [])\n",
    "soft_features = fairness_analysis.get('soft_features', [])\n",
    "\n",
    "categories = ['Técnicas', 'No Técnicas']\n",
    "counts = [len(tech_features), len(soft_features)]\n",
    "\n",
    "axes[plot_idx].pie(counts, labels=categories, autopct='%1.1f%%', startangle=90)\n",
    "axes[plot_idx].set_title('Distribución de Tipos de Características')\n",
    "plot_idx += 1\n",
    "\n",
    "# 6. Análisis de sesgo en probabilidades\n",
    "prob_bins = np.linspace(0, 1, 11)\n",
    "prob_centers = (prob_bins[:-1] + prob_bins[1:]) / 2\n",
    "\n",
    "# Calcular precisión por bin de probabilidad\n",
    "precision_by_prob = []\n",
    "for i in range(len(prob_bins)-1):\n",
    "    mask = (y_combined_proba >= prob_bins[i]) & (y_combined_proba < prob_bins[i+1])\n",
    "    if mask.sum() > 0:\n",
    "        precision = y_combined_true[mask].mean()\n",
    "        precision_by_prob.append(precision)\n",
    "    else:\n",
    "        precision_by_prob.append(0)\n",
    "\n",
    "axes[plot_idx].plot(prob_centers, precision_by_prob, 'bo-', linewidth=2, markersize=6)\n",
    "axes[plot_idx].plot([0, 1], [0, 1], 'r--', alpha=0.7, label='Perfecta calibración')\n",
    "axes[plot_idx].set_xlabel('Probabilidad Predicha')\n",
    "axes[plot_idx].set_ylabel('Precisión Real')\n",
    "axes[plot_idx].set_title('Calibración del Modelo')\n",
    "axes[plot_idx].legend()\n",
    "axes[plot_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fairness_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Análisis de equidad guardado como 'fairness_analysis.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ANÁLISIS DE ROBUSTEZ Y ESTABILIDAD\n",
    "print(\"\\n🛡️ ANÁLISIS DE ROBUSTEZ Y ESTABILIDAD DEL MODELO\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "def analyze_model_robustness(model, X_data, y_true, feature_names):\n",
    "    \"\"\"Analiza la robustez y estabilidad del modelo\"\"\"\n",
    "    \n",
    "    robustness_results = {}\n",
    "    \n",
    "    # 1. Análisis de estabilidad con muestreo bootstrap\n",
    "    print(\"📊 Análisis de estabilidad con bootstrap...\")\n",
    "    \n",
    "    n_bootstrap = 100\n",
    "    bootstrap_metrics = []\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Crear muestra bootstrap\n",
    "        indices = np.random.choice(len(X_data), size=len(X_data), replace=True)\n",
    "        X_boot = X_data.iloc[indices]\n",
    "        y_boot = y_true.iloc[indices]\n",
    "        \n",
    "        # Predecir con el modelo\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_pred_proba = model.predict_proba(X_boot)[:, 1]\n",
    "            y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "        else:\n",
    "            y_pred = model.predict(X_boot)\n",
    "            y_pred_proba = y_pred  # Para modelos sin probabilidades\n",
    "        \n",
    "        # Calcular métricas\n",
    "        accuracy = (y_pred == y_boot).mean()\n",
    "        \n",
    "        if len(np.unique(y_boot)) > 1 and len(np.unique(y_pred)) > 1:\n",
    "            from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "            f1 = f1_score(y_boot, y_pred, average='macro')\n",
    "            precision = precision_score(y_boot, y_pred, average='macro')\n",
    "            recall = recall_score(y_boot, y_pred, average='macro')\n",
    "        else:\n",
    "            f1 = precision = recall = 0\n",
    "        \n",
    "        bootstrap_metrics.append({\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        })\n",
    "    \n",
    "    # Calcular estadísticas de estabilidad\n",
    "    bootstrap_df = pd.DataFrame(bootstrap_metrics)\n",
    "    stability_stats = {\n",
    "        'accuracy_mean': bootstrap_df['accuracy'].mean(),\n",
    "        'accuracy_std': bootstrap_df['accuracy'].std(),\n",
    "        'accuracy_cv': bootstrap_df['accuracy'].std() / bootstrap_df['accuracy'].mean(),\n",
    "        'f1_mean': bootstrap_df['f1_score'].mean(),\n",
    "        'f1_std': bootstrap_df['f1_score'].std(),\n",
    "        'f1_cv': bootstrap_df['f1_score'].std() / max(bootstrap_df['f1_score'].mean(), 0.001)\n",
    "    }\n",
    "    \n",
    "    robustness_results['bootstrap_stability'] = stability_stats\n",
    "    robustness_results['bootstrap_metrics'] = bootstrap_df\n",
    "    \n",
    "    print(f\"  Estabilidad de accuracy: CV = {stability_stats['accuracy_cv']:.3f}\")\n",
    "    print(f\"  Estabilidad de F1: CV = {stability_stats['f1_cv']:.3f}\")\n",
    "    \n",
    "    # 2. Análisis de sensibilidad a perturbaciones\n",
    "    print(\"🔀 Análisis de sensibilidad a perturbaciones...\")\n",
    "    \n",
    "    perturbation_results = {}\n",
    "    noise_levels = [0.01, 0.05, 0.1, 0.2]\n",
    "    \n",
    "    # Predicción baseline\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        baseline_pred = model.predict_proba(X_data)[:, 1]\n",
    "    else:\n",
    "        baseline_pred = model.predict(X_data)\n",
    "    \n",
    "    for noise_level in noise_levels:\n",
    "        # Agregar ruido gaussiano\n",
    "        X_noisy = X_data.copy()\n",
    "        for col in X_data.columns:\n",
    "            if X_data[col].dtype in ['float64', 'int64']:\n",
    "                noise = np.random.normal(0, noise_level * X_data[col].std(), len(X_data))\n",
    "                X_noisy[col] = X_data[col] + noise\n",
    "        \n",
    "        # Predecir con datos ruidosos\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            noisy_pred = model.predict_proba(X_noisy)[:, 1]\n",
    "        else:\n",
    "            noisy_pred = model.predict(X_noisy)\n",
    "        \n",
    "        # Calcular diferencia\n",
    "        pred_diff = np.abs(noisy_pred - baseline_pred).mean()\n",
    "        pred_correlation = np.corrcoef(baseline_pred, noisy_pred)[0, 1]\n",
    "        \n",
    "        perturbation_results[noise_level] = {\n",
    "            'mean_prediction_difference': pred_diff,\n",
    "            'prediction_correlation': pred_correlation\n",
    "        }\n",
    "    \n",
    "    robustness_results['perturbation_analysis'] = perturbation_results\n",
    "    \n",
    "    # 3. Análisis de características influyentes\n",
    "    print(\"🎯 Análisis de características más influyentes...\")\n",
    "    \n",
    "    feature_influence = {}\n",
    "    sample_size = min(200, len(X_data))\n",
    "    X_sample = X_data.sample(sample_size, random_state=42)\n",
    "    \n",
    "    baseline_sample_pred = model.predict_proba(X_sample)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_sample)\n",
    "    \n",
    "    for feature in feature_names[:10]:  # Top 10 features más importantes\n",
    "        if feature in X_sample.columns:\n",
    "            # Perturbar solo esta feature\n",
    "            X_perturbed = X_sample.copy()\n",
    "            \n",
    "            if X_sample[feature].dtype in ['float64', 'int64']:\n",
    "                # Para features numéricas, agregar ruido\n",
    "                X_perturbed[feature] = X_sample[feature] + np.random.normal(0, X_sample[feature].std() * 0.1, sample_size)\n",
    "            else:\n",
    "                # Para features categóricas, shuffle\n",
    "                X_perturbed[feature] = np.random.permutation(X_sample[feature])\n",
    "            \n",
    "            # Predecir con feature perturbada\n",
    "            perturbed_pred = model.predict_proba(X_perturbed)[:, 1] if hasattr(model, 'predict_proba') else model.predict(X_perturbed)\n",
    "            \n",
    "            # Calcular influencia\n",
    "            influence = np.abs(perturbed_pred - baseline_sample_pred).mean()\n",
    "            feature_influence[feature] = influence\n",
    "    \n",
    "    robustness_results['feature_influence'] = feature_influence\n",
    "    \n",
    "    # 4. Análisis de casos límite\n",
    "    print(\"🔍 Análisis de casos límite...\")\n",
    "    \n",
    "    edge_case_analysis = {}\n",
    "    \n",
    "    # Casos con probabilidades cerca del umbral de decisión\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(X_data)[:, 1]\n",
    "        \n",
    "        # Casos cerca del umbral (0.4-0.6)\n",
    "        near_threshold = np.abs(probabilities - 0.5) < 0.1\n",
    "        edge_case_analysis['near_threshold_count'] = near_threshold.sum()\n",
    "        edge_case_analysis['near_threshold_percentage'] = near_threshold.mean()\n",
    "        \n",
    "        # Casos con alta confianza pero incorrectos\n",
    "        high_confidence = np.abs(probabilities - 0.5) > 0.4\n",
    "        if len(y_true) == len(probabilities):\n",
    "            predictions = (probabilities > 0.5).astype(int)\n",
    "            incorrect = predictions != y_true\n",
    "            high_conf_incorrect = high_confidence & incorrect\n",
    "            edge_case_analysis['high_confidence_errors'] = high_conf_incorrect.sum()\n",
    "            edge_case_analysis['high_confidence_error_rate'] = high_conf_incorrect.mean()\n",
    "    \n",
    "    robustness_results['edge_case_analysis'] = edge_case_analysis\n",
    "    \n",
    "    return robustness_results\n",
    "\n",
    "# Realizar análisis de robustez\n",
    "robustness_analysis = analyze_model_robustness(\n",
    "    model, X_combined, y_combined_true, feature_names\n",
    ")\n",
    "\n",
    "# Visualizar análisis de robustez\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_idx = 0\n",
    "\n",
    "# 1. Distribución de métricas bootstrap\n",
    "if 'bootstrap_metrics' in robustness_analysis:\n",
    "    bootstrap_df = robustness_analysis['bootstrap_metrics']\n",
    "    \n",
    "    axes[plot_idx].hist(bootstrap_df['accuracy'], bins=20, alpha=0.7, label='Accuracy', density=True)\n",
    "    axes[plot_idx].hist(bootstrap_df['f1_score'], bins=20, alpha=0.7, label='F1-Score', density=True)\n",
    "    axes[plot_idx].set_xlabel('Valor de Métrica')\n",
    "    axes[plot_idx].set_ylabel('Densidad')\n",
    "    axes[plot_idx].set_title('Distribución de Métricas\\n(Bootstrap Stability)')\n",
    "    axes[plot_idx].legend()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 2. Coeficiente de variación de métricas\n",
    "if 'bootstrap_stability' in robustness_analysis:\n",
    "    stability_data = robustness_analysis['bootstrap_stability']\n",
    "    metrics = ['accuracy_cv', 'f1_cv']\n",
    "    cv_values = [stability_data[m] for m in metrics]\n",
    "    \n",
    "    colors = ['green' if cv < 0.05 else 'orange' if cv < 0.1 else 'red' for cv in cv_values]\n",
    "    \n",
    "    axes[plot_idx].bar(range(len(metrics)), cv_values, color=colors, alpha=0.7)\n",
    "    axes[plot_idx].set_xlabel('Métrica')\n",
    "    axes[plot_idx].set_ylabel('Coeficiente de Variación')\n",
    "    axes[plot_idx].set_title('Estabilidad del Modelo\\n(Verde: Estable, Rojo: Inestable)')\n",
    "    axes[plot_idx].set_xticks(range(len(metrics)))\n",
    "    axes[plot_idx].set_xticklabels(['Accuracy CV', 'F1 CV'])\n",
    "    axes[plot_idx].axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, label='Umbral aceptable')\n",
    "    axes[plot_idx].axhline(y=0.1, color='red', linestyle='--', alpha=0.7, label='Umbral problemático')\n",
    "    axes[plot_idx].legend()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 3. Sensibilidad a perturbaciones\n",
    "if 'perturbation_analysis' in robustness_analysis:\n",
    "    pert_data = robustness_analysis['perturbation_analysis']\n",
    "    noise_levels = list(pert_data.keys())\n",
    "    pred_diffs = [pert_data[level]['mean_prediction_difference'] for level in noise_levels]\n",
    "    correlations = [pert_data[level]['prediction_correlation'] for level in noise_levels]\n",
    "    \n",
    "    axes[plot_idx].plot(noise_levels, pred_diffs, 'ro-', linewidth=2, label='Diferencia Media')\n",
    "    axes[plot_idx].set_xlabel('Nivel de Ruido')\n",
    "    axes[plot_idx].set_ylabel('Diferencia en Predicciones')\n",
    "    axes[plot_idx].set_title('Sensibilidad a Perturbaciones')\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 4. Correlación con perturbaciones\n",
    "axes[plot_idx].plot(noise_levels, correlations, 'bo-', linewidth=2, label='Correlación')\n",
    "axes[plot_idx].set_xlabel('Nivel de Ruido')\n",
    "axes[plot_idx].set_ylabel('Correlación con Baseline')\n",
    "axes[plot_idx].set_title('Correlación bajo Perturbaciones')\n",
    "axes[plot_idx].set_ylim([0, 1])\n",
    "axes[plot_idx].grid(True, alpha=0.3)\n",
    "plot_idx += 1\n",
    "\n",
    "# 5. Influencia de características\n",
    "if 'feature_influence' in robustness_analysis:\n",
    "    influence_data = robustness_analysis['feature_influence']\n",
    "    features = list(influence_data.keys())\n",
    "    influences = list(influence_data.values())\n",
    "    \n",
    "    axes[plot_idx].barh(range(len(features)), influences)\n",
    "    axes[plot_idx].set_yticks(range(len(features)))\n",
    "    axes[plot_idx].set_yticklabels(features)\n",
    "    axes[plot_idx].set_xlabel('Influencia (Diferencia Media)')\n",
    "    axes[plot_idx].set_title('Influencia por Característica')\n",
    "    axes[plot_idx].invert_yaxis()\n",
    "    axes[plot_idx].grid(True, alpha=0.3)\n",
    "    plot_idx += 1\n",
    "\n",
    "# 6. Análisis de casos límite\n",
    "if 'edge_case_analysis' in robustness_analysis:\n",
    "    edge_data = robustness_analysis['edge_case_analysis']\n",
    "    \n",
    "    categories = []\n",
    "    values = []\n",
    "    \n",
    "    if 'near_threshold_percentage' in edge_data:\n",
    "        categories.append('Cerca del\\nUmbral')\n",
    "        values.append(edge_data['near_threshold_percentage'] * 100)\n",
    "    \n",
    "    if 'high_confidence_error_rate' in edge_data:\n",
    "        categories.append('Errores Alta\\nConfianza')\n",
    "        values.append(edge_data['high_confidence_error_rate'] * 100)\n",
    "    \n",
    "    if categories:\n",
    "        colors = ['orange', 'red'][:len(categories)]\n",
    "        axes[plot_idx].bar(range(len(categories)), values, color=colors, alpha=0.7)\n",
    "        axes[plot_idx].set_xlabel('Tipo de Caso Límite')\n",
    "        axes[plot_idx].set_ylabel('Porcentaje (%)')\n",
    "        axes[plot_idx].set_title('Análisis de Casos Límite')\n",
    "        axes[plot_idx].set_xticks(range(len(categories)))\n",
    "        axes[plot_idx].set_xticklabels(categories)\n",
    "        axes[plot_idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('robustness_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Análisis de robustez guardado como 'robustness_analysis.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. REPORTE EJECUTIVO DE INTELIGENCIA ARTIFICIAL RESPONSABLE\n",
    "print(\"\\n📋 REPORTE EJECUTIVO - RAI DASHBOARD\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "def generate_rai_executive_report(explainability_analysis, fairness_analysis, robustness_analysis, model_info):\n",
    "    \"\"\"Genera un reporte ejecutivo completo de RAI\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'model_info': model_info,\n",
    "        'executive_summary': {},\n",
    "        'detailed_findings': {},\n",
    "        'recommendations': [],\n",
    "        'risk_assessment': {},\n",
    "        'compliance_score': {}\n",
    "    }\n",
    "    \n",
    "    # 1. RESUMEN EJECUTIVO\n",
    "    print(\"📊 Generando resumen ejecutivo...\")\n",
    "    \n",
    "    # Explicabilidad\n",
    "    explainability_score = 0\n",
    "    if 'global_importance' in explainability_analysis:\n",
    "        # Score basado en concentración de importancia\n",
    "        importance_df = explainability_analysis['global_importance']\n",
    "        top_5_importance = importance_df.head(5)['importance'].sum()\n",
    "        total_importance = importance_df['importance'].sum()\n",
    "        concentration_ratio = top_5_importance / total_importance if total_importance > 0 else 0\n",
    "        \n",
    "        if concentration_ratio > 0.8:\n",
    "            explainability_score = 85  # Muy concentrado, fácil explicar\n",
    "        elif concentration_ratio > 0.6:\n",
    "            explainability_score = 70  # Moderadamente concentrado\n",
    "        else:\n",
    "            explainability_score = 50  # Muy distribuido, difícil explicar\n",
    "    \n",
    "    # Equidad\n",
    "    fairness_score = 90  # Baseline alto\n",
    "    if 'equity_metrics' in fairness_analysis and fairness_analysis['equity_metrics']:\n",
    "        equity_metrics = fairness_analysis['equity_metrics']\n",
    "        \n",
    "        for metric, value in equity_metrics.items():\n",
    "            if abs(value) > 0.2:\n",
    "                fairness_score -= 30\n",
    "            elif abs(value) > 0.1:\n",
    "                fairness_score -= 15\n",
    "            elif abs(value) > 0.05:\n",
    "                fairness_score -= 5\n",
    "    \n",
    "    # Robustez\n",
    "    robustness_score = 80  # Baseline\n",
    "    if 'bootstrap_stability' in robustness_analysis:\n",
    "        stability_stats = robustness_analysis['bootstrap_stability']\n",
    "        \n",
    "        # Penalizar alta variabilidad\n",
    "        if stability_stats['accuracy_cv'] > 0.1:\n",
    "            robustness_score -= 30\n",
    "        elif stability_stats['accuracy_cv'] > 0.05:\n",
    "            robustness_score -= 15\n",
    "        \n",
    "        if stability_stats['f1_cv'] > 0.1:\n",
    "            robustness_score -= 20\n",
    "        elif stability_stats['f1_cv'] > 0.05:\n",
    "            robustness_score -= 10\n",
    "    \n",
    "    # Score general RAI\n",
    "    overall_rai_score = (explainability_score + fairness_score + robustness_score) / 3\n",
    "    \n",
    "    report['executive_summary'] = {\n",
    "        'overall_rai_score': overall_rai_score,\n",
    "        'explainability_score': explainability_score,\n",
    "        'fairness_score': fairness_score,\n",
    "        'robustness_score': robustness_score,\n",
    "        'rai_level': 'EXCELENTE' if overall_rai_score >= 80 else 'BUENO' if overall_rai_score >= 65 else 'ACEPTABLE' if overall_rai_score >= 50 else 'REQUIERE MEJORAS'\n",
    "    }\n",
    "    \n",
    "    # 2. HALLAZGOS DETALLADOS\n",
    "    detailed_findings = {}\n",
    "    \n",
    "    # Explicabilidad\n",
    "    if 'global_importance' in explainability_analysis:\n",
    "        importance_df = explainability_analysis['global_importance']\n",
    "        detailed_findings['explainability'] = {\n",
    "            'top_3_features': importance_df.head(3)['feature'].tolist(),\n",
    "            'features_for_80_percent': len(importance_df[importance_df['importance'].cumsum() / importance_df['importance'].sum() <= 0.8]),\n",
    "            'importance_concentration': concentration_ratio\n",
    "        }\n",
    "    \n",
    "    # Equidad\n",
    "    if 'demographic_parity' in fairness_analysis and fairness_analysis['demographic_parity']:\n",
    "        parity_data = fairness_analysis['demographic_parity']\n",
    "        positive_rates = [group['predicted_positive_rate'] for group in parity_data.values()]\n",
    "        detailed_findings['fairness'] = {\n",
    "            'max_group_disparity': max(positive_rates) - min(positive_rates),\n",
    "            'number_of_groups_analyzed': len(parity_data),\n",
    "            'groups_with_high_disparity': sum(1 for group in parity_data.values() if abs(group['predicted_positive_rate'] - np.mean(positive_rates)) > 0.1)\n",
    "        }\n",
    "    \n",
    "    # Robustez\n",
    "    if 'bootstrap_stability' in robustness_analysis:\n",
    "        stability_stats = robustness_analysis['bootstrap_stability']\n",
    "        detailed_findings['robustness'] = {\n",
    "            'accuracy_stability_cv': stability_stats['accuracy_cv'],\n",
    "            'f1_stability_cv': stability_stats['f1_cv'],\n",
    "            'model_stability_level': 'ALTA' if max(stability_stats['accuracy_cv'], stability_stats['f1_cv']) < 0.05 else 'MEDIA' if max(stability_stats['accuracy_cv'], stability_stats['f1_cv']) < 0.1 else 'BAJA'\n",
    "        }\n",
    "    \n",
    "    report['detailed_findings'] = detailed_findings\n",
    "    \n",
    "    # 3. RECOMENDACIONES\n",
    "    recommendations = []\n",
    "    \n",
    "    # Recomendaciones de explicabilidad\n",
    "    if explainability_score < 70:\n",
    "        recommendations.append({\n",
    "            'category': 'Explicabilidad',\n",
    "            'priority': 'ALTA',\n",
    "            'recommendation': 'Simplificar el modelo o implementar técnicas de interpretabilidad local para mejorar la explicabilidad',\n",
    "            'action_items': ['Implementar LIME o SHAP para explicaciones locales', 'Considerar modelos más simples', 'Documentar las características más importantes']\n",
    "        })\n",
    "    \n",
    "    # Recomendaciones de equidad\n",
    "    if fairness_score < 70:\n",
    "        recommendations.append({\n",
    "            'category': 'Equidad',\n",
    "            'priority': 'ALTA',\n",
    "            'recommendation': 'Abordar sesgos detectados en el modelo mediante técnicas de mitigación',\n",
    "            'action_items': ['Rebalancear datos de entrenamiento', 'Implementar restricciones de equidad', 'Monitorear métricas de equidad en producción']\n",
    "        })\n",
    "    \n",
    "    # Recomendaciones de robustez\n",
    "    if robustness_score < 70:\n",
    "        recommendations.append({\n",
    "            'category': 'Robustez',\n",
    "            'priority': 'MEDIA',\n",
    "            'recommendation': 'Mejorar la estabilidad del modelo mediante técnicas de regularización',\n",
    "            'action_items': ['Aumentar datos de entrenamiento', 'Aplicar técnicas de regularización', 'Implementar validación cruzada robusta']\n",
    "        })\n",
    "    \n",
    "    # Recomendaciones generales\n",
    "    if overall_rai_score >= 80:\n",
    "        recommendations.append({\n",
    "            'category': 'General',\n",
    "            'priority': 'BAJA',\n",
    "            'recommendation': 'Mantener monitoreo continuo y documentación de RAI',\n",
    "            'action_items': ['Implementar monitoreo en tiempo real', 'Crear documentación de RAI', 'Establecer revisiones periódicas']\n",
    "        })\n",
    "    \n",
    "    report['recommendations'] = recommendations\n",
    "    \n",
    "    # 4. EVALUACIÓN DE RIESGOS\n",
    "    risk_level = 'BAJO'\n",
    "    risk_factors = []\n",
    "    \n",
    "    if explainability_score < 50:\n",
    "        risk_factors.append('Modelo difícil de explicar')\n",
    "        risk_level = 'ALTO'\n",
    "    elif explainability_score < 70:\n",
    "        risk_factors.append('Explicabilidad limitada')\n",
    "        if risk_level == 'BAJO':\n",
    "            risk_level = 'MEDIO'\n",
    "    \n",
    "    if fairness_score < 50:\n",
    "        risk_factors.append('Sesgos significativos detectados')\n",
    "        risk_level = 'ALTO'\n",
    "    elif fairness_score < 70:\n",
    "        risk_factors.append('Posibles sesgos menores')\n",
    "        if risk_level == 'BAJO':\n",
    "            risk_level = 'MEDIO'\n",
    "    \n",
    "    if robustness_score < 50:\n",
    "        risk_factors.append('Modelo inestable')\n",
    "        risk_level = 'ALTO'\n",
    "    elif robustness_score < 70:\n",
    "        risk_factors.append('Estabilidad moderada')\n",
    "        if risk_level == 'BAJO':\n",
    "            risk_level = 'MEDIO'\n",
    "    \n",
    "    report['risk_assessment'] = {\n",
    "        'overall_risk_level': risk_level,\n",
    "        'risk_factors': risk_factors,\n",
    "        'mitigation_priority': 'INMEDIATA' if risk_level == 'ALTO' else 'CORTO_PLAZO' if risk_level == 'MEDIO' else 'LARGO_PLAZO'\n",
    "    }\n",
    "    \n",
    "    # 5. PUNTUACIÓN DE CUMPLIMIENTO\n",
    "    compliance_score = {\n",
    "        'gdpr_compliance': 85 if explainability_score > 70 else 60,  # Derecho a explicación\n",
    "        'ai_ethics_score': overall_rai_score,\n",
    "        'regulatory_readiness': 90 if overall_rai_score > 75 and len(risk_factors) == 0 else 70 if overall_rai_score > 60 else 50\n",
    "    }\n",
    "    \n",
    "    report['compliance_score'] = compliance_score\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generar reporte RAI\n",
    "rai_report = generate_rai_executive_report(\n",
    "    explainability_analysis, \n",
    "    fairness_analysis, \n",
    "    robustness_analysis,\n",
    "    {\n",
    "        'model_name': training_info['best_model_name'],\n",
    "        'model_version': registered_model.version,\n",
    "        'feature_count': len(feature_names),\n",
    "        'training_samples': len(X_combined)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Visualizar dashboard ejecutivo RAI\n",
    "fig, axes = plt.subplots(3, 3, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 1. Score general RAI\n",
    "scores = [\n",
    "    rai_report['executive_summary']['explainability_score'],\n",
    "    rai_report['executive_summary']['fairness_score'],\n",
    "    rai_report['executive_summary']['robustness_score'],\n",
    "    rai_report['executive_summary']['overall_rai_score']\n",
    "]\n",
    "labels = ['Explicabilidad', 'Equidad', 'Robustez', 'RAI General']\n",
    "colors = ['green' if s >= 80 else 'orange' if s >= 65 else 'red' for s in scores]\n",
    "\n",
    "axes[0].bar(range(len(labels)), scores, color=colors, alpha=0.8)\n",
    "axes[0].set_ylabel('Puntuación')\n",
    "axes[0].set_title('Puntuaciones RAI')\n",
    "axes[0].set_xticks(range(len(labels)))\n",
    "axes[0].set_xticklabels(labels, rotation=45)\n",
    "axes[0].set_ylim([0, 100])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, score in enumerate(scores):\n",
    "    axes[0].text(i, score + 2, f'{score:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Nivel de riesgo\n",
    "risk_level = rai_report['risk_assessment']['overall_risk_level']\n",
    "risk_colors = {'BAJO': 'green', 'MEDIO': 'orange', 'ALTO': 'red'}\n",
    "risk_color = risk_colors.get(risk_level, 'gray')\n",
    "\n",
    "axes[1].pie([1], labels=[f'Riesgo\\n{risk_level}'], colors=[risk_color], autopct='', startangle=90)\n",
    "axes[1].set_title('Nivel de Riesgo General')\n",
    "\n",
    "# 3. Cumplimiento regulatorio\n",
    "compliance_data = rai_report['compliance_score']\n",
    "comp_labels = ['GDPR', 'Ética IA', 'Preparación\\nRegulatoria']\n",
    "comp_values = [compliance_data['gdpr_compliance'], compliance_data['ai_ethics_score'], compliance_data['regulatory_readiness']]\n",
    "\n",
    "axes[2].bar(range(len(comp_labels)), comp_values, color=['blue', 'purple', 'teal'], alpha=0.7)\n",
    "axes[2].set_ylabel('Puntuación')\n",
    "axes[2].set_title('Cumplimiento Regulatorio')\n",
    "axes[2].set_xticks(range(len(comp_labels)))\n",
    "axes[2].set_xticklabels(comp_labels)\n",
    "axes[2].set_ylim([0, 100])\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Top características más importantes\n",
    "if 'explainability' in rai_report['detailed_findings']:\n",
    "    top_features = rai_report['detailed_findings']['explainability']['top_3_features']\n",
    "    axes[3].barh(range(len(top_features)), [3, 2, 1], color='lightblue', alpha=0.8)\n",
    "    axes[3].set_yticks(range(len(top_features)))\n",
    "    axes[3].set_yticklabels(top_features)\n",
    "    axes[3].set_xlabel('Ranking de Importancia')\n",
    "    axes[3].set_title('Top 3 Características\\nMás Importantes')\n",
    "    axes[3].invert_yaxis()\n",
    "\n",
    "# 5. Distribución de recomendaciones por prioridad\n",
    "if rai_report['recommendations']:\n",
    "    priorities = [rec['priority'] for rec in rai_report['recommendations']]\n",
    "    priority_counts = pd.Series(priorities).value_counts()\n",
    "    \n",
    "    colors_priority = {'ALTA': 'red', 'MEDIA': 'orange', 'BAJA': 'green'}\n",
    "    colors = [colors_priority.get(p, 'gray') for p in priority_counts.index]\n",
    "    \n",
    "    axes[4].pie(priority_counts.values, labels=priority_counts.index, colors=colors, autopct='%1.0f', startangle=90)\n",
    "    axes[4].set_title('Distribución de\\nRecomendaciones por Prioridad')\n",
    "\n",
    "# 6. Timeline de implementación sugerido\n",
    "implementation_timeline = {\n",
    "    'Inmediato (0-1 mes)': len([r for r in rai_report['recommendations'] if r['priority'] == 'ALTA']),\n",
    "    'Corto plazo (1-3 meses)': len([r for r in rai_report['recommendations'] if r['priority'] == 'MEDIA']),\n",
    "    'Largo plazo (3+ meses)': len([r for r in rai_report['recommendations'] if r['priority'] == 'BAJA'])\n",
    "}\n",
    "\n",
    "timeline_labels = list(implementation_timeline.keys())\n",
    "timeline_values = list(implementation_timeline.values())\n",
    "\n",
    "axes[5].bar(range(len(timeline_labels)), timeline_values, color=['red', 'orange', 'green'], alpha=0.7)\n",
    "axes[5].set_ylabel('Número de Acciones')\n",
    "axes[5].set_title('Timeline de Implementación')\n",
    "axes[5].set_xticks(range(len(timeline_labels)))\n",
    "axes[5].set_xticklabels(timeline_labels, rotation=45, ha='right')\n",
    "\n",
    "# 7. Matriz de riesgo vs impacto\n",
    "risk_impact_data = []\n",
    "for rec in rai_report['recommendations']:\n",
    "    priority_to_risk = {'ALTA': 3, 'MEDIA': 2, 'BAJA': 1}\n",
    "    category_to_impact = {'Explicabilidad': 3, 'Equidad': 3, 'Robustez': 2, 'General': 1}\n",
    "    \n",
    "    risk_level = priority_to_risk.get(rec['priority'], 1)\n",
    "    impact_level = category_to_impact.get(rec['category'], 1)\n",
    "    risk_impact_data.append((risk_level, impact_level, rec['category']))\n",
    "\n",
    "if risk_impact_data:\n",
    "    x_vals = [item[0] for item in risk_impact_data]\n",
    "    y_vals = [item[1] for item in risk_impact_data]\n",
    "    colors_scatter = ['red' if x >= 3 else 'orange' if x >= 2 else 'green' for x in x_vals]\n",
    "    \n",
    "    axes[6].scatter(x_vals, y_vals, c=colors_scatter, alpha=0.7, s=100)\n",
    "    axes[6].set_xlabel('Nivel de Riesgo')\n",
    "    axes[6].set_ylabel('Nivel de Impacto')\n",
    "    axes[6].set_title('Matriz Riesgo vs Impacto')\n",
    "    axes[6].set_xlim([0.5, 3.5])\n",
    "    axes[6].set_ylim([0.5, 3.5])\n",
    "    axes[6].grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Tendencia de mejora sugerida\n",
    "months = ['Mes 1', 'Mes 3', 'Mes 6', 'Mes 12']\n",
    "current_score = rai_report['executive_summary']['overall_rai_score']\n",
    "projected_scores = [\n",
    "    current_score,\n",
    "    current_score + 10,  # Mejoras rápidas\n",
    "    current_score + 20,  # Mejoras sustanciales\n",
    "    min(95, current_score + 25)  # Mejoras a largo plazo\n",
    "]\n",
    "\n",
    "axes[7].plot(months, projected_scores, 'bo-', linewidth=3, markersize=8)\n",
    "axes[7].fill_between(months, projected_scores, alpha=0.3)\n",
    "axes[7].set_ylabel('Puntuación RAI')\n",
    "axes[7].set_title('Proyección de Mejora RAI')\n",
    "axes[7].set_ylim([0, 100])\n",
    "axes[7].grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Resumen de estado actual\n",
    "status_text = f\"\"\"\n",
    "ESTADO ACTUAL RAI\n",
    "\n",
    "Puntuación General: {rai_report['executive_summary']['overall_rai_score']:.0f}/100\n",
    "Nivel: {rai_report['executive_summary']['rai_level']}\n",
    "\n",
    "Riesgo: {rai_report['risk_assessment']['overall_risk_level']}\n",
    "Recomendaciones: {len(rai_report['recommendations'])}\n",
    "\n",
    "Cumplimiento GDPR: {rai_report['compliance_score']['gdpr_compliance']:.0f}%\n",
    "Preparación Regulatoria: {rai_report['compliance_score']['regulatory_readiness']:.0f}%\n",
    "\"\"\"\n",
    "\n",
    "axes[8].text(0.05, 0.95, status_text, transform=axes[8].transAxes, fontsize=10,\n",
    "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "axes[8].set_xlim([0, 1])\n",
    "axes[8].set_ylim([0, 1])\n",
    "axes[8].axis('off')\n",
    "axes[8].set_title('Resumen Ejecutivo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rai_executive_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Dashboard ejecutivo RAI guardado como 'rai_executive_dashboard.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. REGISTRO EN AZURE ML Y GENERACIÓN DE DOCUMENTACIÓN FINAL\n",
    "print(\"\\n🔄 REGISTRO RAI EN AZURE ML Y DOCUMENTACIÓN\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Crear experimento para RAI\n",
    "RAI_EXPERIMENT = \"candidate-rai-analysis\"\n",
    "\n",
    "with mlflow.start_run(experiment_id=mlflow.create_experiment(RAI_EXPERIMENT) if RAI_EXPERIMENT not in [exp.name for exp in mlflow.search_experiments()] else mlflow.get_experiment_by_name(RAI_EXPERIMENT).experiment_id):\n",
    "    \n",
    "    # Registrar métricas RAI en MLflow\n",
    "    print(\"📊 Registrando métricas RAI...\")\n",
    "    \n",
    "    # Puntuaciones principales\n",
    "    mlflow.log_metric(\"rai_overall_score\", rai_report['executive_summary']['overall_rai_score'])\n",
    "    mlflow.log_metric(\"explainability_score\", rai_report['executive_summary']['explainability_score'])\n",
    "    mlflow.log_metric(\"fairness_score\", rai_report['executive_summary']['fairness_score'])\n",
    "    mlflow.log_metric(\"robustness_score\", rai_report['executive_summary']['robustness_score'])\n",
    "    \n",
    "    # Métricas de cumplimiento\n",
    "    mlflow.log_metric(\"gdpr_compliance_score\", rai_report['compliance_score']['gdpr_compliance'])\n",
    "    mlflow.log_metric(\"ai_ethics_score\", rai_report['compliance_score']['ai_ethics_score'])\n",
    "    mlflow.log_metric(\"regulatory_readiness_score\", rai_report['compliance_score']['regulatory_readiness'])\n",
    "    \n",
    "    # Métricas de robustez detalladas\n",
    "    if 'bootstrap_stability' in robustness_analysis:\n",
    "        stability_stats = robustness_analysis['bootstrap_stability']\n",
    "        mlflow.log_metric(\"accuracy_cv\", stability_stats['accuracy_cv'])\n",
    "        mlflow.log_metric(\"f1_cv\", stability_stats['f1_cv'])\n",
    "        mlflow.log_metric(\"accuracy_stability_mean\", stability_stats['accuracy_mean'])\n",
    "        mlflow.log_metric(\"f1_stability_mean\", stability_stats['f1_mean'])\n",
    "    \n",
    "    # Métricas de equidad\n",
    "    if 'equity_metrics' in fairness_analysis and fairness_analysis['equity_metrics']:\n",
    "        equity_metrics = fairness_analysis['equity_metrics']\n",
    "        for metric_name, value in equity_metrics.items():\n",
    "            mlflow.log_metric(f\"fairness_{metric_name}\", value)\n",
    "    \n",
    "    # Registrar parámetros\n",
    "    mlflow.log_param(\"evaluated_model\", training_info['best_model_name'])\n",
    "    mlflow.log_param(\"model_version\", registered_model.version)\n",
    "    mlflow.log_param(\"rai_analysis_date\", pd.Timestamp.now().strftime('%Y-%m-%d'))\n",
    "    mlflow.log_param(\"risk_level\", rai_report['risk_assessment']['overall_risk_level'])\n",
    "    mlflow.log_param(\"rai_level\", rai_report['executive_summary']['rai_level'])\n",
    "    mlflow.log_param(\"recommendations_count\", len(rai_report['recommendations']))\n",
    "    \n",
    "    # Registrar características más importantes\n",
    "    if 'explainability' in rai_report['detailed_findings']:\n",
    "        top_features = rai_report['detailed_findings']['explainability']['top_3_features']\n",
    "        for i, feature in enumerate(top_features, 1):\n",
    "            mlflow.log_param(f\"top_explainable_feature_{i}\", feature)\n",
    "    \n",
    "    # Registrar artefactos (visualizaciones)\n",
    "    print(\"🖼️ Registrando visualizaciones RAI...\")\n",
    "    mlflow.log_artifact(\"explainability_analysis.png\")\n",
    "    mlflow.log_artifact(\"fairness_analysis.png\") \n",
    "    mlflow.log_artifact(\"robustness_analysis.png\")\n",
    "    mlflow.log_artifact(\"rai_executive_dashboard.png\")\n",
    "    \n",
    "    # Guardar reporte RAI completo como JSON\n",
    "    rai_report_clean = {}\n",
    "    for key, value in rai_report.items():\n",
    "        if isinstance(value, dict):\n",
    "            rai_report_clean[key] = {k: v for k, v in value.items() if not isinstance(v, pd.DataFrame)}\n",
    "        else:\n",
    "            rai_report_clean[key] = value\n",
    "    \n",
    "    with open('rai_complete_report.json', 'w') as f:\n",
    "        json.dump(rai_report_clean, f, indent=2, default=str)\n",
    "    \n",
    "    mlflow.log_artifact('rai_complete_report.json')\n",
    "    \n",
    "    current_run = mlflow.active_run()\n",
    "    rai_run_id = current_run.info.run_id\n",
    "    \n",
    "    print(f\"✅ Análisis RAI registrado en MLflow\")\n",
    "    print(f\"📋 Run ID: {rai_run_id}\")\n",
    "\n",
    "# Generar reporte de texto detallado\n",
    "print(\"\\n📄 Generando documentación RAI detallada...\")\n",
    "\n",
    "rai_documentation = f\"\"\"\n",
    "# REPORTE DE INTELIGENCIA ARTIFICIAL RESPONSABLE (RAI)\n",
    "## Modelo de Selección de Candidatos\n",
    "\n",
    "**Fecha de análisis:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Modelo evaluado:** {training_info['best_model_name']} v{registered_model.version}\n",
    "**Run ID de análisis:** {rai_run_id}\n",
    "\n",
    "---\n",
    "\n",
    "## RESUMEN EJECUTIVO\n",
    "\n",
    "### Puntuaciones Generales\n",
    "- **Puntuación RAI General:** {rai_report['executive_summary']['overall_rai_score']:.0f}/100 ({rai_report['executive_summary']['rai_level']})\n",
    "- **Explicabilidad:** {rai_report['executive_summary']['explainability_score']:.0f}/100\n",
    "- **Equidad:** {rai_report['executive_summary']['fairness_score']:.0f}/100\n",
    "- **Robustez:** {rai_report['executive_summary']['robustness_score']:.0f}/100\n",
    "\n",
    "### Evaluación de Riesgo\n",
    "- **Nivel de riesgo:** {rai_report['risk_assessment']['overall_risk_level']}\n",
    "- **Prioridad de mitigación:** {rai_report['risk_assessment']['mitigation_priority']}\n",
    "\n",
    "### Cumplimiento Regulatorio\n",
    "- **Cumplimiento GDPR:** {rai_report['compliance_score']['gdpr_compliance']:.0f}%\n",
    "- **Preparación regulatoria:** {rai_report['compliance_score']['regulatory_readiness']:.0f}%\n",
    "\n",
    "---\n",
    "\n",
    "## ANÁLISIS DETALLADO\n",
    "\n",
    "### 1. EXPLICABILIDAD DEL MODELO\n",
    "\"\"\"\n",
    "\n",
    "if 'explainability' in rai_report['detailed_findings']:\n",
    "    explainability_findings = rai_report['detailed_findings']['explainability']\n",
    "    rai_documentation += f\"\"\"\n",
    "**Características más importantes:**\n",
    "\"\"\"\n",
    "    for i, feature in enumerate(explainability_findings['top_3_features'], 1):\n",
    "        rai_documentation += f\"{i}. {feature}\\n\"\n",
    "    \n",
    "    rai_documentation += f\"\"\"\n",
    "**Concentración de importancia:** {explainability_findings['importance_concentration']:.2f}\n",
    "**Características para 80% de explicación:** {explainability_findings['features_for_80_percent']}\n",
    "\n",
    "**Interpretación:** \"\"\"\n",
    "    if explainability_findings['importance_concentration'] > 0.8:\n",
    "        rai_documentation += \"El modelo es altamente explicable con pocas características dominantes.\"\n",
    "    elif explainability_findings['importance_concentration'] > 0.6:\n",
    "        rai_documentation += \"El modelo tiene explicabilidad moderada con características importantes bien definidas.\"\n",
    "    else:\n",
    "        rai_documentation += \"El modelo distribuye importancia entre muchas características, requiere técnicas adicionales de explicabilidad.\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "### 2. ANÁLISIS DE EQUIDAD\n",
    "\"\"\"\n",
    "\n",
    "if 'fairness' in rai_report['detailed_findings']:\n",
    "    fairness_findings = rai_report['detailed_findings']['fairness']\n",
    "    rai_documentation += f\"\"\"\n",
    "**Grupos analizados:** {fairness_findings['number_of_groups_analyzed']}\n",
    "**Disparidad máxima entre grupos:** {fairness_findings['max_group_disparity']:.3f}\n",
    "**Grupos con alta disparidad:** {fairness_findings['groups_with_high_disparity']}\n",
    "\n",
    "**Interpretación:** \"\"\"\n",
    "    if fairness_findings['max_group_disparity'] < 0.05:\n",
    "        rai_documentation += \"El modelo muestra alta equidad entre grupos analizados.\"\n",
    "    elif fairness_findings['max_group_disparity'] < 0.1:\n",
    "        rai_documentation += \"El modelo muestra equidad aceptable con disparidades menores.\"\n",
    "    else:\n",
    "        rai_documentation += \"Se detectaron disparidades significativas que requieren atención.\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "### 3. ANÁLISIS DE ROBUSTEZ\n",
    "\"\"\"\n",
    "\n",
    "if 'robustness' in rai_report['detailed_findings']:\n",
    "    robustness_findings = rai_report['detailed_findings']['robustness']\n",
    "    rai_documentation += f\"\"\"\n",
    "**Coeficiente de variación - Accuracy:** {robustness_findings['accuracy_stability_cv']:.4f}\n",
    "**Coeficiente de variación - F1:** {robustness_findings['f1_stability_cv']:.4f}\n",
    "**Nivel de estabilidad:** {robustness_findings['model_stability_level']}\n",
    "\n",
    "**Interpretación:** \"\"\"\n",
    "    if robustness_findings['model_stability_level'] == 'ALTA':\n",
    "        rai_documentation += \"El modelo muestra alta estabilidad y robustez.\"\n",
    "    elif robustness_findings['model_stability_level'] == 'MEDIA':\n",
    "        rai_documentation += \"El modelo tiene estabilidad moderada, aceptable para producción.\"\n",
    "    else:\n",
    "        rai_documentation += \"El modelo muestra baja estabilidad y requiere mejoras antes de producción.\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## RECOMENDACIONES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i, rec in enumerate(rai_report['recommendations'], 1):\n",
    "    rai_documentation += f\"\"\"\n",
    "### {i}. {rec['category']} (Prioridad: {rec['priority']})\n",
    "**Recomendación:** {rec['recommendation']}\n",
    "\n",
    "**Acciones específicas:**\n",
    "\"\"\"\n",
    "    for action in rec['action_items']:\n",
    "        rai_documentation += f\"- {action}\\n\"\n",
    "    rai_documentation += \"\\n\"\n",
    "\n",
    "if rai_report['risk_assessment']['risk_factors']:\n",
    "    rai_documentation += f\"\"\"\n",
    "---\n",
    "\n",
    "## FACTORES DE RIESGO IDENTIFICADOS\n",
    "\n",
    "\"\"\"\n",
    "    for i, risk_factor in enumerate(rai_report['risk_assessment']['risk_factors'], 1):\n",
    "        rai_documentation += f\"{i}. {risk_factor}\\n\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "---\n",
    "\n",
    "## CONCLUSIONES Y PRÓXIMOS PASOS\n",
    "\n",
    "### Estado Actual\n",
    "El modelo presenta un nivel RAI **{rai_report['executive_summary']['rai_level']}** con una puntuación de {rai_report['executive_summary']['overall_rai_score']:.0f}/100. El riesgo general se clasifica como **{rai_report['risk_assessment']['overall_risk_level']}**.\n",
    "\n",
    "### Recomendaciones Prioritarias\n",
    "\"\"\"\n",
    "\n",
    "high_priority_recs = [r for r in rai_report['recommendations'] if r['priority'] == 'ALTA']\n",
    "if high_priority_recs:\n",
    "    rai_documentation += f\"Se requiere atención inmediata en {len(high_priority_recs)} área(s) crítica(s):\\n\"\n",
    "    for rec in high_priority_recs:\n",
    "        rai_documentation += f\"- {rec['category']}: {rec['recommendation']}\\n\"\n",
    "else:\n",
    "    rai_documentation += \"No se identificaron áreas que requieran atención inmediata.\\n\"\n",
    "\n",
    "rai_documentation += f\"\"\"\n",
    "\n",
    "### Siguientes Pasos\n",
    "1. **Inmediato (0-1 mes):** Implementar recomendaciones de alta prioridad\n",
    "2. **Corto plazo (1-3 meses):** Abordar recomendaciones de prioridad media\n",
    "3. **Largo plazo (3+ meses):** Implementar mejoras adicionales y monitoreo continuo\n",
    "\n",
    "### Monitoreo Continuo\n",
    "- Revisar métricas RAI cada 3 meses\n",
    "- Monitorear equidad en producción\n",
    "- Actualizar documentación de explicabilidad\n",
    "- Evaluar nuevos riesgos emergentes\n",
    "\n",
    "---\n",
    "\n",
    "**Documento generado automáticamente por el sistema RAI**\n",
    "**Última actualización:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "# Guardar documentación\n",
    "with open('rai_detailed_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(rai_documentation)\n",
    "\n",
    "# Registro en MLflow\n",
    "with mlflow.start_run(run_id=rai_run_id):\n",
    "    mlflow.log_artifact('rai_detailed_report.md')\n",
    "\n",
    "print(f\"✅ Documentación RAI completa generada\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(f\"\\n🎯 RESUMEN FINAL DEL ANÁLISIS RAI\")\n",
    "print(\"=\"*55)\n",
    "print(f\"📊 Puntuación RAI General: {rai_report['executive_summary']['overall_rai_score']:.0f}/100\")\n",
    "print(f\"🏆 Nivel RAI: {rai_report['executive_summary']['rai_level']}\")\n",
    "print(f\"⚠️  Nivel de riesgo: {rai_report['risk_assessment']['overall_risk_level']}\")\n",
    "print(f\"📋 Recomendaciones generadas: {len(rai_report['recommendations'])}\")\n",
    "print(f\"🔄 Run ID RAI: {rai_run_id}\")\n",
    "\n",
    "print(f\"\\n📁 ARCHIVOS GENERADOS:\")\n",
    "print(f\"  - explainability_analysis.png\")\n",
    "print(f\"  - fairness_analysis.png\") \n",
    "print(f\"  - robustness_analysis.png\")\n",
    "print(f\"  - rai_executive_dashboard.png\")\n",
    "print(f\"  - rai_complete_report.json\")\n",
    "print(f\"  - rai_detailed_report.md\")\n",
    "\n",
    "print(f\"\\n✅ ANÁLISIS RAI COMPLETADO\")\n",
    "print(f\"🔗 Todos los artefactos disponibles en Azure ML Studio\")\n",
    "print(f\"📋 Experimento: {RAI_EXPERIMENT}\")\n",
    "\n",
    "# Guardar métricas finales para reporte\n",
    "final_rai_metrics = {\n",
    "    'overall_score': rai_report['executive_summary']['overall_rai_score'],\n",
    "    'risk_level': rai_report['risk_assessment']['overall_risk_level'],\n",
    "    'recommendations_count': len(rai_report['recommendations']),\n",
    "    'high_priority_recommendations': len([r for r in rai_report['recommendations'] if r['priority'] == 'ALTA']),\n",
    "    'compliance_ready': rai_report['compliance_score']['regulatory_readiness'] >= 70\n",
    "}\n",
    "\n",
    "print(f\"\\n📈 MÉTRICAS FINALES PARA SEGUIMIENTO:\")\n",
    "for metric, value in final_rai_metrics.items():\n",
    "    print(f\"  {metric}: {value}\")\n",
    "\n",
    "print(f\"\\n🎉 Pipeline RAI completo exitosamente!\")\n",
    "print(f\"🔄 Ready para revisión ejecutiva y implementación en producción\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
